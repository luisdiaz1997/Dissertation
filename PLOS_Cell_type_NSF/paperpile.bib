@ARTICLE{Hoffman2012-dm,
  title    = "Stochastic variational inference",
  author   = "Hoffman, M and Blei, D and Wang, Chong and Paisley, J",
  journal  = "J. Mach. Learn. Res.",
  volume   =  14,
  pages    = "1303--1347",
  abstract = "We develop stochastic variational inference, a scalable algorithm
              for approximating posterior distributions. We develop this
              technique for a large class of probabilistic models and we
              demonstrate it with two probabilistic topic models, latent
              Dirichlet allocation and the hierarchical Dirichlet process topic
              model. Using stochastic variational inference, we analyze several
              large collections of documents: 300K articles from Nature, 1.8M
              articles from The New York Times, and 3.8M articles from
              Wikipedia. Stochastic inference can easily handle data sets of
              this size and outperforms traditional variational inference, which
              can only handle a smaller subset. (We also show that the Bayesian
              nonparametric topic model outperforms its parametric counterpart.)
              Stochastic variational inference lets us apply complex Bayesian
              models to massive data sets.",
  month    =  jun,
  year     =  2012
}

@ARTICLE{Hensman2013-xr,
  title         = "Gaussian Processes for Big Data",
  author        = "Hensman, James and Fusi, Nicolo and Lawrence, Neil D",
  journal       = "arXiv [cs.LG]",
  abstract      = "We introduce stochastic variational inference for Gaussian
                   process models. This enables the application of Gaussian
                   process (GP) models to data sets containing millions of data
                   points. We show how GPs can be vari- ationally decomposed to
                   depend on a set of globally relevant inducing variables which
                   factorize the model in the necessary manner to perform
                   variational inference. Our ap- proach is readily extended to
                   models with non-Gaussian likelihoods and latent variable
                   models based around Gaussian processes. We demonstrate the
                   approach on a simple toy problem and two real world data
                   sets.",
  month         =  sep,
  year          =  2013,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Gal2014-mp,
  title         = "Variational Inference in Sparse Gaussian Process Regression
                   and Latent Variable Models - a Gentle Tutorial",
  author        = "Gal, Yarin and van der Wilk, Mark",
  journal       = "arXiv [stat.ML]",
  abstract      = "In this tutorial we explain the inference procedures
                   developed for the sparse Gaussian process (GP) regression and
                   Gaussian process latent variable model (GPLVM). Due to page
                   limit the derivation given in Titsias (2009) and Titsias \&
                   Lawrence (2010) is brief, hence getting a full picture of it
                   requires collecting results from several different sources
                   and a substantial amount of algebra to fill-in the gaps. Our
                   main goal is thus to collect all the results and full
                   derivations into one place to help speed up understanding
                   this work. In doing so we present a re-parametrisation of the
                   inference that allows it to be carried out in parallel. A
                   secondary goal for this document is, therefore, to accompany
                   our paper and open-source implementation of the parallel
                   inference scheme for the models. We hope that this document
                   will bridge the gap between the equations as implemented in
                   code and those published in the original papers, in order to
                   make it easier to extend existing work. We assume prior
                   knowledge of Gaussian processes and variational inference,
                   but we also include references for further reading where
                   appropriate.",
  month         =  feb,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{Gal2014-ph,
  title         = "Variational Inference in Sparse Gaussian Process Regression
                   and Latent Variable Models - a Gentle Tutorial",
  author        = "Gal, Yarin and van der Wilk, Mark",
  journal       = "arXiv [stat.ML]",
  abstract      = "In this tutorial we explain the inference procedures
                   developed for the sparse Gaussian process (GP) regression and
                   Gaussian process latent variable model (GPLVM). Due to page
                   limit the derivation given in Titsias (2009) and Titsias \&
                   Lawrence (2010) is brief, hence getting a full picture of it
                   requires collecting results from several different sources
                   and a substantial amount of algebra to fill-in the gaps. Our
                   main goal is thus to collect all the results and full
                   derivations into one place to help speed up understanding
                   this work. In doing so we present a re-parametrisation of the
                   inference that allows it to be carried out in parallel. A
                   secondary goal for this document is, therefore, to accompany
                   our paper and open-source implementation of the parallel
                   inference scheme for the models. We hope that this document
                   will bridge the gap between the equations as implemented in
                   code and those published in the original papers, in order to
                   make it easier to extend existing work. We assume prior
                   knowledge of Gaussian processes and variational inference,
                   but we also include references for further reading where
                   appropriate.",
  month         =  feb,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{Kingma2014-wg,
  title         = "Adam: A Method for Stochastic Optimization",
  author        = "Kingma, Diederik P and Ba, Jimmy",
  journal       = "arXiv [cs.LG]",
  abstract      = "We introduce Adam, an algorithm for first-order
                   gradient-based optimization of stochastic objective
                   functions, based on adaptive estimates of lower-order
                   moments. The method is straightforward to implement, is
                   computationally efficient, has little memory requirements, is
                   invariant to diagonal rescaling of the gradients, and is well
                   suited for problems that are large in terms of data and/or
                   parameters. The method is also appropriate for non-stationary
                   objectives and problems with very noisy and/or sparse
                   gradients. The hyper-parameters have intuitive
                   interpretations and typically require little tuning. Some
                   connections to related algorithms, on which Adam was
                   inspired, are discussed. We also analyze the theoretical
                   convergence properties of the algorithm and provide a regret
                   bound on the convergence rate that is comparable to the best
                   known results under the online convex optimization framework.
                   Empirical results demonstrate that Adam works well in
                   practice and compares favorably to other stochastic
                   optimization methods. Finally, we discuss AdaMax, a variant
                   of Adam based on the infinity norm.",
  month         =  dec,
  year          =  2014,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Abadi2016-lb,
  title         = "{TensorFlow}: Large-Scale Machine Learning on Heterogeneous
                   Distributed Systems",
  author        = "Abadi, Martín and Agarwal, Ashish and Barham, Paul and
                   Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and
                   Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin,
                   Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp,
                   Andrew and Irving, Geoffrey and Isard, Michael and Jia,
                   Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur,
                   Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat
                   and Moore, Sherry and Murray, Derek and Olah, Chris and
                   Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and
                   Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and
                   Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda
                   and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin
                   and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang",
  journal       = "arXiv [cs.DC]",
  abstract      = "TensorFlow is an interface for expressing machine learning
                   algorithms, and an implementation for executing such
                   algorithms. A computation expressed using TensorFlow can be
                   executed with little or no change on a wide variety of
                   heterogeneous systems, ranging from mobile devices such as
                   phones and tablets up to large-scale distributed systems of
                   hundreds of machines and thousands of computational devices
                   such as GPU cards. The system is flexible and can be used to
                   express a wide variety of algorithms, including training and
                   inference algorithms for deep neural network models, and it
                   has been used for conducting research and for deploying
                   machine learning systems into production across more than a
                   dozen areas of computer science and other fields, including
                   speech recognition, computer vision, robotics, information
                   retrieval, natural language processing, geographic
                   information extraction, and computational drug discovery.
                   This paper describes the TensorFlow interface and an
                   implementation of that interface that we have built at
                   Google. The TensorFlow API and a reference implementation
                   were released as an open-source package under the Apache 2.0
                   license in November, 2015 and are available at
                   www.tensorflow.org.",
  month         =  mar,
  year          =  2016,
  archivePrefix = "arXiv",
  primaryClass  = "cs.DC"
}

@ARTICLE{Salimbeni2017-gl,
  title         = "Doubly Stochastic Variational Inference for Deep Gaussian
                   Processes",
  author        = "Salimbeni, Hugh and Deisenroth, Marc",
  journal       = "arXiv [stat.ML]",
  abstract      = "Gaussian processes (GPs) are a good choice for function
                   approximation as they are flexible, robust to over-fitting,
                   and provide well-calibrated predictive uncertainty. Deep
                   Gaussian processes (DGPs) are multi-layer generalisations of
                   GPs, but inference in these models has proved challenging.
                   Existing approaches to inference in DGP models assume
                   approximate posteriors that force independence between the
                   layers, and do not work well in practice. We present a doubly
                   stochastic variational inference algorithm, which does not
                   force independence between layers. With our method of
                   inference we demonstrate that a DGP model can be used
                   effectively on data ranging in size from hundreds to a
                   billion points. We provide strong empirical evidence that our
                   inference scheme for DGPs works well in practice in both
                   classification and regression.",
  month         =  may,
  year          =  2017,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ML"
}

@ARTICLE{Uhrenholt2020-ty,
  title         = "Probabilistic selection of inducing points in sparse Gaussian
                   processes",
  author        = "Uhrenholt, Anders Kirk and Charvet, Valentin and Jensen,
                   Bjørn Sand",
  journal       = "arXiv [cs.LG]",
  abstract      = "Sparse Gaussian processes and various extensions thereof are
                   enabled through inducing points, that simultaneously
                   bottleneck the predictive capacity and act as the main
                   contributor towards model complexity. However, the number of
                   inducing points is generally not associated with uncertainty
                   which prevents us from applying the apparatus of Bayesian
                   reasoning for identifying an appropriate trade-off. In this
                   work we place a point process prior on the inducing points
                   and approximate the associated posterior through stochastic
                   variational inference. By letting the prior encourage a
                   moderate number of inducing points, we enable the model to
                   learn which and how many points to utilise. We experimentally
                   show that fewer inducing points are preferred by the model as
                   the points become less informative, and further demonstrate
                   how the method can be employed in deep Gaussian processes and
                   latent variable modelling.",
  month         =  oct,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{William_Townes2021-tm,
  title         = "Nonnegative spatial factorization",
  author        = "William Townes, F and Engelhardt, Barbara E",
  journal       = "arXiv [stat.ME]",
  abstract      = "Gaussian processes are widely used for the analysis of
                   spatial data due to their nonparametric flexibility and
                   ability to quantify uncertainty, and recently developed
                   scalable approximations have facilitated application to
                   massive datasets. For multivariate outcomes, linear models of
                   coregionalization combine dimension reduction with spatial
                   correlation. However, their real-valued latent factors and
                   loadings are difficult to interpret because, unlike
                   nonnegative models, they do not recover a parts-based
                   representation. We present nonnegative spatial factorization
                   (NSF), a spatially-aware probabilistic dimension reduction
                   model that naturally encourages sparsity. We compare NSF to
                   real-valued spatial factorizations such as MEFISTO and
                   nonspatial dimension reduction methods using simulations and
                   high-dimensional spatial transcriptomics data. NSF identifies
                   generalizable spatial patterns of gene expression. Since not
                   all patterns of gene expression are spatial, we also propose
                   a hybrid extension of NSF that combines spatial and
                   nonspatial components, enabling quantification of spatial
                   importance for both observations and features. A TensorFlow
                   implementation of NSF is available from
                   https://github.com/willtownes/nsf-paper .",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ME"
}

@ARTICLE{Li2021-mu,
  title         = "Multi-group Gaussian Processes",
  author        = "Li, Didong and Jones, Andrew and Banerjee, Sudipto and
                   Engelhardt, Barbara E",
  journal       = "arXiv [stat.ME]",
  abstract      = "Gaussian processes (GPs) are pervasive in functional data
                   analysis, machine learning, and spatial statistics for
                   modeling complex dependencies. Modern scientific data sets
                   are typically heterogeneous and often contain multiple known
                   discrete subgroups of samples. For example, in genomics
                   applications samples may be grouped according to tissue type
                   or drug exposure. In the modeling process it is desirable to
                   leverage the similarity among groups while accounting for
                   differences between them. While a substantial literature
                   exists for GPs over Euclidean domains $\mathbb{R}^p$, GPs on
                   domains suitable for multi-group data remain less explored.
                   Here, we develop a multi-group Gaussian process (MGGP), which
                   we define on $\mathbb{R}^p\times \mathscr{C}$, where
                   $\mathscr{C}$ is a finite set representing the group label.
                   We provide general methods to construct valid (positive
                   definite) covariance functions on this domain, and we
                   describe algorithms for inference, estimation, and
                   prediction. We perform simulation experiments and apply MGGP
                   to gene expression data to illustrate the behavior and
                   advantages of the MGGP in the joint modeling of continuous
                   and categorical variables.",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ME"
}

@ARTICLE{Li2021-fv,
  title         = "Multi-group Gaussian Processes",
  author        = "Li, Didong and Jones, Andrew and Banerjee, Sudipto and
                   Engelhardt, Barbara E",
  journal       = "arXiv [stat.ME]",
  abstract      = "Gaussian processes (GPs) are pervasive in functional data
                   analysis, machine learning, and spatial statistics for
                   modeling complex dependencies. Modern scientific data sets
                   are typically heterogeneous and often contain multiple known
                   discrete subgroups of samples. For example, in genomics
                   applications samples may be grouped according to tissue type
                   or drug exposure. In the modeling process it is desirable to
                   leverage the similarity among groups while accounting for
                   differences between them. While a substantial literature
                   exists for GPs over Euclidean domains $\mathbb{R}^p$, GPs on
                   domains suitable for multi-group data remain less explored.
                   Here, we develop a multi-group Gaussian process (MGGP), which
                   we define on $\mathbb{R}^p\times \mathscr{C}$, where
                   $\mathscr{C}$ is a finite set representing the group label.
                   We provide general methods to construct valid (positive
                   definite) covariance functions on this domain, and we
                   describe algorithms for inference, estimation, and
                   prediction. We perform simulation experiments and apply MGGP
                   to gene expression data to illustrate the behavior and
                   advantages of the MGGP in the joint modeling of continuous
                   and categorical variables.",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "stat.ME"
}

@ARTICLE{Lalchand2022-kv,
  title         = "Generalised Gaussian Process Latent Variable Models ({GPLVM})
                   with Stochastic Variational Inference",
  author        = "Lalchand, Vidhi and Ravuri, Aditya and Lawrence, Neil D",
  journal       = "arXiv [cs.LG]",
  abstract      = "Gaussian process latent variable models (GPLVM) are a
                   flexible and non-linear approach to dimensionality reduction,
                   extending classical Gaussian processes to an unsupervised
                   learning context. The Bayesian incarnation of the GPLVM
                   Titsias and Lawrence, 2010] uses a variational framework,
                   where the posterior over latent variables is approximated by
                   a well-behaved variational family, a factorized Gaussian
                   yielding a tractable lower bound. However, the non-factories
                   ability of the lower bound prevents truly scalable inference.
                   In this work, we study the doubly stochastic formulation of
                   the Bayesian GPLVM model amenable with minibatch training. We
                   show how this framework is compatible with different latent
                   variable formulations and perform experiments to compare a
                   suite of models. Further, we demonstrate how we can train in
                   the presence of massively missing data and obtain
                   high-fidelity reconstructions. We demonstrate the model's
                   performance by benchmarking against the canonical sparse
                   GPLVM for high-dimensional data examples.",
  month         =  feb,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Lalchand2022-qr,
  title         = "Generalised Gaussian Process Latent Variable Models ({GPLVM})
                   with Stochastic Variational Inference",
  author        = "Lalchand, Vidhi and Ravuri, Aditya and Lawrence, Neil D",
  journal       = "arXiv [cs.LG]",
  abstract      = "Gaussian process latent variable models (GPLVM) are a
                   flexible and non-linear approach to dimensionality reduction,
                   extending classical Gaussian processes to an unsupervised
                   learning context. The Bayesian incarnation of the GPLVM
                   Titsias and Lawrence, 2010] uses a variational framework,
                   where the posterior over latent variables is approximated by
                   a well-behaved variational family, a factorized Gaussian
                   yielding a tractable lower bound. However, the non-factories
                   ability of the lower bound prevents truly scalable inference.
                   In this work, we study the doubly stochastic formulation of
                   the Bayesian GPLVM model amenable with minibatch training. We
                   show how this framework is compatible with different latent
                   variable formulations and perform experiments to compare a
                   suite of models. Further, we demonstrate how we can train in
                   the presence of massively missing data and obtain
                   high-fidelity reconstructions. We demonstrate the model's
                   performance by benchmarking against the canonical sparse
                   GPLVM for high-dimensional data examples.",
  month         =  feb,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@MISC{Rasmussen_undated-ft,
  title        = "Gaussian processes for machine learning",
  author       = "Rasmussen, C E and Williams, C K I",
  howpublished = "\url{ftp://nozdr.ru/biblio/kolxoz/Cs/CsAi/Rasmussen\%20C.,\%20Williams\%20C.\%20Gaussian\%20Processes\%20for\%20Machine\%20Learning(MIT,\%202006)(ISBN\%20026218253X)(266s)\_CsAi\_.pdf}",
  note         = "Accessed: 2023-2-28"
}

@ARTICLE{Wakim2021-mb,
  title    = "Impact of chromosomal organization on epigenetic drift and domain
              stability revealed by physics-based simulations",
  author   = "Wakim, Joseph G and Sandholtz, Sarah H and Spakowitz, Andrew J",
  journal  = "Biophys. J.",
  volume   =  120,
  number   =  22,
  pages    = "4932--4943",
  abstract = "We examine the relationship between the size of domains of
              epigenetic marks and the stability of those domains using our
              theoretical model that captures the physical mechanisms governing
              the maintenance of epigenetic modifications. We focus our study on
              histone H3 lysine-9 trimethylation, one of the most common and
              consequential epigenetic marks with roles in chromatin compaction
              and gene repression. Our model combines the effects of methyl
              spreading by methyltransferases and chromatin segregation into
              heterochromatin and euchromatin because of preferential
              heterochromatin protein 1 (HP1) binding. Our model indicates that,
              although large methylated domains are passed successfully from one
              chromatin generation to the next, small alterations to the
              methylation sequence are not maintained during chromatin
              replication. Using our predictive model, we investigate the size
              required for an epigenetic domain to persist over chromatin
              generations while surrounded by a much larger domain of opposite
              methylation and compaction state. We find that there is a critical
              size threshold in the hundreds-of-nucleosomes scale above which an
              epigenetic domain will be reliably maintained over generations.
              The precise size of the threshold differs for heterochromatic and
              euchromatic domains. Our results are consistent with natural
              alterations to the epigenetic sequence occurring during embryonic
              development and due to age-related epigenetic drift.",
  month    =  nov,
  year     =  2021,
  language = "en"
}

@ARTICLE{Rao2014-uc,
  title    = "A {3D} map of the human genome at kilobase resolution reveals
              principles of chromatin looping",
  author   = "Rao, Suhas S P and Huntley, Miriam H and Durand, Neva C and
              Stamenova, Elena K and Bochkov, Ivan D and Robinson, James T and
              Sanborn, Adrian L and Machol, Ido and Omer, Arina D and Lander,
              Eric S and Aiden, Erez Lieberman",
  journal  = "Cell",
  volume   =  159,
  number   =  7,
  pages    = "1665--1680",
  abstract = "We use in situ Hi-C to probe the 3D architecture of genomes,
              constructing haploid and diploid maps of nine cell types. The
              densest, in human lymphoblastoid cells, contains 4.9 billion
              contacts, achieving 1 kb resolution. We find that genomes are
              partitioned into contact domains (median length, 185 kb), which
              are associated with distinct patterns of histone marks and
              segregate into six subcompartments. We identify ∼10,000 loops.
              These loops frequently link promoters and enhancers, correlate
              with gene activation, and show conservation across cell types and
              species. Loop anchors typically occur at domain boundaries and
              bind CTCF. CTCF sites at loop anchors occur predominantly (>90\%)
              in a convergent orientation, with the asymmetric motifs ``facing''
              one another. The inactive X chromosome splits into two massive
              domains and contains large loops anchored at CTCF-binding repeats.",
  month    =  dec,
  year     =  2014,
  language = "en"
}

@ARTICLE{Rao2014-or,
  title    = "A {3D} map of the human genome at kilobase resolution reveals
              principles of chromatin looping",
  author   = "Rao, Suhas S P and Huntley, Miriam H and Durand, Neva C and
              Stamenova, Elena K and Bochkov, Ivan D and Robinson, James T and
              Sanborn, Adrian L and Machol, Ido and Omer, Arina D and Lander,
              Eric S and Aiden, Erez Lieberman",
  journal  = "Cell",
  volume   =  159,
  number   =  7,
  pages    = "1665--1680",
  abstract = "We use in situ Hi-C to probe the 3D architecture of genomes,
              constructing haploid and diploid maps of nine cell types. The
              densest, in human lymphoblastoid cells, contains 4.9 billion
              contacts, achieving 1 kb resolution. We find that genomes are
              partitioned into contact domains (median length, 185 kb), which
              are associated with distinct patterns of histone marks and
              segregate into six subcompartments. We identify ∼10,000 loops.
              These loops frequently link promoters and enhancers, correlate
              with gene activation, and show conservation across cell types and
              species. Loop anchors typically occur at domain boundaries and
              bind CTCF. CTCF sites at loop anchors occur predominantly (>90\%)
              in a convergent orientation, with the asymmetric motifs ``facing''
              one another. The inactive X chromosome splits into two massive
              domains and contains large loops anchored at CTCF-binding repeats.",
  month    =  dec,
  year     =  2014,
  language = "en"
}

@ARTICLE{Johnstone2020-qe,
  title    = "Large-Scale Topological Changes Restrain Malignant Progression in
              Colorectal Cancer",
  author   = "Johnstone, Sarah E and Reyes, Alejandro and Qi, Yifeng and
              Adriaens, Carmen and Hegazi, Esmat and Pelka, Karin and Chen,
              Jonathan H and Zou, Luli S and Drier, Yotam and Hecht, Vivian and
              Shoresh, Noam and Selig, Martin K and Lareau, Caleb A and Iyer,
              Sowmya and Nguyen, Son C and Joyce, Eric F and Hacohen, Nir and
              Irizarry, Rafael A and Zhang, Bin and Aryee, Martin J and
              Bernstein, Bradley E",
  journal  = "Cell",
  volume   =  182,
  number   =  6,
  pages    = "1474--1489.e23",
  abstract = "Widespread changes to DNA methylation and chromatin are well
              documented in cancer, but the fate of higher-order chromosomal
              structure remains obscure. Here we integrated topological maps for
              colon tumors and normal colons with epigenetic, transcriptional,
              and imaging data to characterize alterations to chromatin loops,
              topologically associated domains, and large-scale compartments. We
              found that spatial partitioning of the open and closed genome
              compartments is profoundly compromised in tumors. This
              reorganization is accompanied by compartment-specific
              hypomethylation and chromatin changes. Additionally, we identify a
              compartment at the interface between the canonical A and B
              compartments that is reorganized in tumors. Remarkably, similar
              shifts were evident in non-malignant cells that have accumulated
              excess divisions. Our analyses suggest that these topological
              changes repress stemness and invasion programs while inducing
              anti-tumor immunity genes and may therefore restrain malignant
              progression. Our findings call into question the conventional view
              that tumor-associated epigenomic alterations are primarily
              oncogenic.",
  month    =  sep,
  year     =  2020,
  keywords = "DNA methylation; chromatin; colon cancer; compartment;
              epigenetics; genome topology; nuclear architecture",
  language = "en"
}

@ARTICLE{Fudenberg2016-gu,
  title    = "Formation of Chromosomal Domains by Loop Extrusion",
  author   = "Fudenberg, Geoffrey and Imakaev, Maxim and Lu, Carolyn and
              Goloborodko, Anton and Abdennur, Nezar and Mirny, Leonid A",
  journal  = "Cell Rep.",
  volume   =  15,
  number   =  9,
  pages    = "2038--2049",
  abstract = "Topologically associating domains (TADs) are fundamental
              structural and functional building blocks of human interphase
              chromosomes, yet the mechanisms of TAD formation remain unclear.
              Here, we propose that loop extrusion underlies TAD formation. In
              this process, cis-acting loop-extruding factors, likely cohesins,
              form progressively larger loops but stall at TAD boundaries due to
              interactions with boundary proteins, including CTCF. Using polymer
              simulations, we show that this model produces TADs and finer-scale
              features of Hi-C data. Each TAD emerges from multiple loops
              dynamically formed through extrusion, contrary to typical
              illustrations of single static loops. Loop extrusion both explains
              diverse experimental observations-including the preferential
              orientation of CTCF motifs, enrichments of architectural proteins
              at TAD boundaries, and boundary deletion experiments-and makes
              specific predictions for the depletion of CTCF versus cohesin.
              Finally, loop extrusion has potentially far-ranging consequences
              for processes such as enhancer-promoter interactions,
              orientation-specific chromosomal looping, and compaction of
              mitotic chromosomes.",
  month    =  may,
  year     =  2016,
  language = "en"
}

@ARTICLE{Nichols2021-km,
  title    = "Principles of {3D} compartmentalization of the human genome",
  author   = "Nichols, Michael H and Corces, Victor G",
  journal  = "Cell Rep.",
  volume   =  35,
  number   =  13,
  pages    =  109330,
  abstract = "Chromatin is organized in the nucleus via CTCF loops and
              compartmental domains. Here, we compare different cell types to
              identify distinct paradigms of compartmental domain formation in
              human tissues. We identify and quantify compartmental forces
              correlated with histone modifications characteristic of
              transcriptional activity and previously underappreciated roles for
              distinct compartmental domains correlated with the presence of
              H3K27me3 and H3K9me3, respectively. We present a computer
              simulation model capable of predicting compartmental organization
              based on the biochemical characteristics of independent chromatin
              features. Using this model, we show that the underlying forces
              responsible for compartmental domain formation in human cells are
              conserved and that the diverse compartmentalization patterns seen
              across cell types are due to differences in chromatin features. We
              extend these findings to Drosophila to suggest that the same
              principles are at work beyond humans. These results offer
              mechanistic insights into the fundamental forces driving the 3D
              organization of the genome.",
  month    =  jun,
  year     =  2021,
  keywords = "3D organization; CTCF; chromatin; cohesin; enhancer; nucleus;
              transcription",
  language = "en"
}

@ARTICLE{Salahian2023-pl,
  title     = "Deep autoencoder-like {NMF} with contrastive regularization and
               feature relationship preservation",
  author    = "Salahian, Navid and Tab, Fardin Akhlaghian and Seyedi, Seyed
               Amjad and Chavoshinejad, Jovan",
  journal   = "Expert Syst. Appl.",
  publisher = "Elsevier BV",
  volume    =  214,
  number    =  119051,
  pages     =  119051,
  abstract  = "Nonnegative Matrix Factorization is a data analysis method to
               discover parts-based, linear representations of data. It has been
               successfully used in a…",
  month     =  mar,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Wang2024-ln,
  title     = "An autoencoder-like deep {NMF} representation learning algorithm
               for clustering",
  author    = "Wang, Dexian and Zhang, Pengfei and Deng, Ping and Wu, Qiaofeng
               and Chen, Wei and Jiang, Tao and Huang, Wei and Li, Tianrui",
  journal   = "Knowl. Based Syst.",
  publisher = "Elsevier BV",
  volume    =  305,
  number    =  112597,
  pages     =  112597,
  abstract  = "Clustering plays a crucial role in the field of data mining,
               where deep non-negative matrix factorization (NMF) has attracted
               significant attention du…",
  month     =  dec,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Buckle2018-lf,
  title    = "Polymer Simulations of Heteromorphic Chromatin Predict the {3D}
              Folding of Complex Genomic Loci",
  author   = "Buckle, Adam and Brackley, Chris A and Boyle, Shelagh and
              Marenduzzo, Davide and Gilbert, Nick",
  journal  = "Mol. Cell",
  volume   =  72,
  number   =  4,
  pages    = "786--797.e11",
  abstract = "Chromatin folded into 3D macromolecular structures is often
              analyzed by chromosome conformation capture (3C) and fluorescence
              in situ hybridization (FISH) techniques, but these frequently
              provide contradictory results. Chromatin can be modeled as a
              simple polymer composed of a connected chain of units. By
              embedding data for epigenetic marks (H3K27ac), chromatin
              accessibility (assay for transposase-accessible chromatin using
              sequencing [ATAC-seq]), and structural anchors (CCCTC-binding
              factor [CTCF]), we developed a highly predictive heteromorphic
              polymer (HiP-HoP) model, where the chromatin fiber varied along
              its length; combined with diffusing protein bridges and loop
              extrusion, this model predicted the 3D organization of genomic
              loci at a population and single-cell level. The model was
              validated at several gene loci, including the complex Pax6 gene,
              and was able to determine locus conformations across cell types
              with varying levels of transcriptional activity and explain
              different mechanisms of enhancer use. Minimal a priori knowledge
              of epigenetic marks is sufficient to recapitulate complex genomic
              loci in 3D and enable predictions of chromatin folding paths.",
  month    =  nov,
  year     =  2018,
  keywords = "3C; Capture-C; FISH; chromatin; enhancer; genome organization;
              histone modifications; polymer modeling; transcription",
  language = "en"
}

@ARTICLE{McCord2020-gq,
  title    = "Chromosome Conformation Capture and Beyond: Toward an Integrative
              View of Chromosome Structure and Function",
  author   = "McCord, Rachel Patton and Kaplan, Noam and Giorgetti, Luca",
  journal  = "Mol. Cell",
  volume   =  77,
  number   =  4,
  pages    = "688--708",
  abstract = "Rapidly developing technologies have recently fueled an exciting
              era of discovery in the field of chromosome structure and nuclear
              organization. In addition to chromosome conformation capture (3C)
              methods, new alternative techniques have emerged to study genome
              architecture and biological processes in the nucleus, often in
              single or living cells. This sets an unprecedented stage for
              exploring the mechanisms that link chromosome structure and
              biological function. Here we review popular as well as emerging
              approaches to study chromosome organization, focusing on the
              contribution of complementary methodologies to our understanding
              of structures revealed by 3C methods and their biological
              implications, and discuss the next technical and conceptual
              frontiers.",
  month    =  feb,
  year     =  2020,
  language = "en"
}

@ARTICLE{Aron2006-vy,
  title     = "Long-term test-retest reliability of functional {MRI} in a
               classification learning task",
  author    = "Aron, Adam R and Gluck, Mark A and Poldrack, Russell A",
  journal   = "Neuroimage",
  publisher = "Elsevier BV",
  volume    =  29,
  number    =  3,
  pages     = "1000--1006",
  abstract  = "Functional MRI is widely used for imaging the neural correlates
               of psychological processes and how these brain processes change
               with learning, development and neuropsychiatric disorder. In
               order to interpret changes in imaging signals over time, for
               example, in patient studies, the long-term reliability of fMRI
               must first be established. Here, eight healthy adult subjects
               were scanned on two sessions, 1 year apart, while performing a
               classification learning task known to activate frontostriatal
               circuitry. We show that behavioral performance and frontostriatal
               activation were highly concordant at a group level at both
               time-points. Furthermore, intra-class correlation coefficients
               (ICCs), which index the degree of correlation between subjects at
               different time-points, were high for behavior and for functional
               activation. ICC was significantly higher within the network
               recruited by learning than outside that network. We conclude that
               fMRI can have high long-term test-retest reliability, making it
               suitable as a biomarker for brain development and
               neurodegeneration.",
  month     =  feb,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Van-Essen2013-te,
  title     = "The {WU}-Minn Human Connectome Project: an overview",
  author    = "Van Essen, David C and Smith, Stephen M and Barch, Deanna M and
               Behrens, Timothy E J and Yacoub, Essa and Ugurbil, Kamil and
               {WU-Minn HCP Consortium}",
  journal   = "Neuroimage",
  publisher = "Academic Press",
  volume    =  80,
  pages     = "62--79",
  abstract  = "The Human Connectome Project consortium led by Washington
               University, University of Minnesota, and Oxford University is
               undertaking a systematic effort to map macroscopic human brain
               circuits and their relationship to behavior in a large population
               of healthy adults. This overview article focuses on progress made
               during the first half of the 5-year project in refining the
               methods for data acquisition and analysis. Preliminary analyses
               based on a finalized set of acquisition and preprocessing
               protocols demonstrate the exceptionally high quality of the data
               from each modality. The first quarterly release of imaging and
               behavioral data via the ConnectomeDB database demonstrates the
               commitment to making HCP datasets freely accessible. Altogether,
               the progress to date provides grounds for optimism that the HCP
               datasets and associated methods and software will become
               increasingly valuable resources for characterizing human brain
               connectivity and function, their relationship to behavior, and
               their heritability and genetic underpinnings.",
  month     =  oct,
  year      =  2013,
  language  = "en"
}

@ARTICLE{Wu2021-yn,
  title     = "Brain kernel: A new spatial covariance function for {fMRI} data",
  author    = "Wu, Anqi and Nastase, Samuel A and Baldassano, Christopher A and
               Turk-Browne, Nicholas B and Norman, Kenneth A and Engelhardt,
               Barbara E and Pillow, Jonathan W",
  journal   = "Neuroimage",
  publisher = "Elsevier BV",
  volume    =  245,
  number    =  118580,
  pages     =  118580,
  abstract  = "A key problem in functional magnetic resonance imaging (fMRI) is
               to estimate spatial activity patterns from noisy high-dimensional
               signals. Spatial smoothing provides one approach to regularizing
               such estimates. However, standard smoothing methods ignore the
               fact that correlations in neural activity may fall off at
               different rates in different brain areas, or exhibit
               discontinuities across anatomical or functional boundaries.
               Moreover, such methods do not exploit the fact that widely
               separated brain regions may exhibit strong correlations due to
               bilateral symmetry or the network organization of brain regions.
               To capture this non-stationary spatial correlation structure, we
               introduce the brain kernel, a continuous covariance function for
               whole-brain activity patterns. We define the brain kernel in
               terms of a continuous nonlinear mapping from 3D brain coordinates
               to a latent embedding space, parametrized with a Gaussian process
               (GP). The brain kernel specifies the prior covariance between
               voxels as a function of the distance between their locations in
               embedding space. The GP mapping warps the brain nonlinearly so
               that highly correlated voxels are close together in latent space,
               and uncorrelated voxels are far apart. We estimate the brain
               kernel using resting-state fMRI data, and we develop an exact,
               scalable inference method based on block coordinate descent to
               overcome the challenges of high dimensionality (10-100K voxels).
               Finally, we illustrate the brain kernel's usefulness with
               applications to brain decoding and factor analysis with multiple
               task-based fMRI datasets.",
  month     =  dec,
  year      =  2021,
  keywords  = "Brain decoding; Brain kernel; Factor modeling; Gaussian process;
               Latent variable model; Resting-state fmri; Task fmri",
  language  = "en"
}

@ARTICLE{Wiltschko2015-my,
  title    = "Mapping Sub-Second Structure in Mouse Behavior",
  author   = "Wiltschko, Alexander B and Johnson, Matthew J and Iurilli,
              Giuliano and Peterson, Ralph E and Katon, Jesse M and Pashkovski,
              Stan L and Abraira, Victoria E and Adams, Ryan P and Datta,
              Sandeep Robert",
  journal  = "Neuron",
  volume   =  88,
  number   =  6,
  pages    = "1121--1135",
  abstract = "Complex animal behaviors are likely built from simpler modules,
              but their systematic identification in mammals remains a
              significant challenge. Here we use depth imaging to show that 3D
              mouse pose dynamics are structured at the sub-second timescale.
              Computational modeling of these fast dynamics effectively
              describes mouse behavior as a series of reused and stereotyped
              modules with defined transition probabilities. We demonstrate this
              combined 3D imaging and machine learning method can be used to
              unmask potential strategies employed by the brain to adapt to the
              environment, to capture both predicted and previously hidden
              phenotypes caused by genetic or neural manipulations, and to
              systematically expose the global structure of behavior within an
              experiment. This work reveals that mouse body language is built
              from identifiable components and is organized in a predictable
              fashion; deciphering this language establishes an objective
              framework for characterizing the influence of environmental cues,
              genes and neural activity on behavior.",
  month    =  dec,
  year     =  2015,
  language = "en"
}

@ARTICLE{Lajoie2015-mh,
  title    = "The Hitchhiker's guide to Hi-{C} analysis: practical guidelines",
  author   = "Lajoie, Bryan R and Dekker, Job and Kaplan, Noam",
  journal  = "Methods",
  volume   =  72,
  pages    = "65--75",
  abstract = "Over the last decade, development and application of a set of
              molecular genomic approaches based on the chromosome conformation
              capture method (3C), combined with increasingly powerful imaging
              approaches, have enabled high resolution and genome-wide analysis
              of the spatial organization of chromosomes. The aim of this paper
              is to provide guidelines for analyzing and interpreting data
              obtained with genome-wide 3C methods such as Hi-C and 3C-seq that
              rely on deep sequencing to detect and quantify pairwise chromatin
              interactions.",
  month    =  jan,
  year     =  2015,
  keywords = "Bioinformatics; Chromatin structure; Chromosome conformation
              capture; Deep sequencing; Hi-C",
  language = "en"
}

@ARTICLE{Lee1999-lo,
  title    = "Learning the parts of objects by non-negative matrix factorization",
  author   = "Lee, D D and Seung, H S",
  journal  = "Nature",
  volume   =  401,
  number   =  6755,
  pages    = "788--791",
  abstract = "Is perception of the whole based on perception of its parts? There
              is psychological and physiological evidence for parts-based
              representations in the brain, and certain computational theories
              of object recognition rely on such representations. But little is
              known about how brains or computers might learn the parts of
              objects. Here we demonstrate an algorithm for non-negative matrix
              factorization that is able to learn parts of faces and semantic
              features of text. This is in contrast to other methods, such as
              principal components analysis and vector quantization, that learn
              holistic, not parts-based, representations. Non-negative matrix
              factorization is distinguished from the other methods by its use
              of non-negativity constraints. These constraints lead to a
              parts-based representation because they allow only additive, not
              subtractive, combinations. When non-negative matrix factorization
              is implemented as a neural network, parts-based representations
              emerge by virtue of two properties: the firing rates of neurons
              are never negative and synaptic strengths do not change sign.",
  month    =  oct,
  year     =  1999,
  language = "en"
}

@ARTICLE{Lee1999-au,
  title    = "Learning the parts of objects by non-negative matrix factorization",
  author   = "Lee, D D and Seung, H S",
  journal  = "Nature",
  volume   =  401,
  number   =  6755,
  pages    = "788--791",
  abstract = "Is perception of the whole based on perception of its parts? There
              is psychological and physiological evidence for parts-based
              representations in the brain, and certain computational theories
              of object recognition rely on such representations. But little is
              known about how brains or computers might learn the parts of
              objects. Here we demonstrate an algorithm for non-negative matrix
              factorization that is able to learn parts of faces and semantic
              features of text. This is in contrast to other methods, such as
              principal components analysis and vector quantization, that learn
              holistic, not parts-based, representations. Non-negative matrix
              factorization is distinguished from the other methods by its use
              of non-negativity constraints. These constraints lead to a
              parts-based representation because they allow only additive, not
              subtractive, combinations. When non-negative matrix factorization
              is implemented as a neural network, parts-based representations
              emerge by virtue of two properties: the firing rates of neurons
              are never negative and synaptic strengths do not change sign.",
  month    =  oct,
  year     =  1999,
  language = "en"
}

@ARTICLE{Lee1999-su,
  title    = "Learning the parts of objects by non-negative matrix factorization",
  author   = "Lee, D D and Seung, H S",
  journal  = "Nature",
  volume   =  401,
  number   =  6755,
  pages    = "788--791",
  abstract = "Is perception of the whole based on perception of its parts? There
              is psychological and physiological evidence for parts-based
              representations in the brain, and certain computational theories
              of object recognition rely on such representations. But little is
              known about how brains or computers might learn the parts of
              objects. Here we demonstrate an algorithm for non-negative matrix
              factorization that is able to learn parts of faces and semantic
              features of text. This is in contrast to other methods, such as
              principal components analysis and vector quantization, that learn
              holistic, not parts-based, representations. Non-negative matrix
              factorization is distinguished from the other methods by its use
              of non-negativity constraints. These constraints lead to a
              parts-based representation because they allow only additive, not
              subtractive, combinations. When non-negative matrix factorization
              is implemented as a neural network, parts-based representations
              emerge by virtue of two properties: the firing rates of neurons
              are never negative and synaptic strengths do not change sign.",
  month    =  oct,
  year     =  1999,
  language = "en"
}

@ARTICLE{Dixon2012-bg,
  title    = "Topological domains in mammalian genomes identified by analysis of
              chromatin interactions",
  author   = "Dixon, Jesse R and Selvaraj, Siddarth and Yue, Feng and Kim,
              Audrey and Li, Yan and Shen, Yin and Hu, Ming and Liu, Jun S and
              Ren, Bing",
  journal  = "Nature",
  volume   =  485,
  number   =  7398,
  pages    = "376--380",
  abstract = "The spatial organization of the genome is intimately linked to its
              biological function, yet our understanding of higher order genomic
              structure is coarse, fragmented and incomplete. In the nucleus of
              eukaryotic cells, interphase chromosomes occupy distinct
              chromosome territories, and numerous models have been proposed for
              how chromosomes fold within chromosome territories. These models,
              however, provide only few mechanistic details about the
              relationship between higher order chromatin structure and genome
              function. Recent advances in genomic technologies have led to
              rapid advances in the study of three-dimensional genome
              organization. In particular, Hi-C has been introduced as a method
              for identifying higher order chromatin interactions genome wide.
              Here we investigate the three-dimensional organization of the
              human and mouse genomes in embryonic stem cells and terminally
              differentiated cell types at unprecedented resolution. We identify
              large, megabase-sized local chromatin interaction domains, which
              we term 'topological domains', as a pervasive structural feature
              of the genome organization. These domains correlate with regions
              of the genome that constrain the spread of heterochromatin. The
              domains are stable across different cell types and highly
              conserved across species, indicating that topological domains are
              an inherent property of mammalian genomes. Finally, we find that
              the boundaries of topological domains are enriched for the
              insulator binding protein CTCF, housekeeping genes, transfer RNAs
              and short interspersed element (SINE) retrotransposons, indicating
              that these factors may have a role in establishing the topological
              domain structure of the genome.",
  month    =  apr,
  year     =  2012,
  language = "en"
}

@ARTICLE{Crane2015-xf,
  title    = "Condensin-driven remodelling of {X} chromosome topology during
              dosage compensation",
  author   = "Crane, Emily and Bian, Qian and McCord, Rachel Patton and Lajoie,
              Bryan R and Wheeler, Bayly S and Ralston, Edward J and Uzawa,
              Satoru and Dekker, Job and Meyer, Barbara J",
  journal  = "Nature",
  volume   =  523,
  number   =  7559,
  pages    = "240--244",
  abstract = "The three-dimensional organization of a genome plays a critical
              role in regulating gene expression, yet little is known about the
              machinery and mechanisms that determine higher-order chromosome
              structure. Here we perform genome-wide chromosome conformation
              capture analysis, fluorescent in situ hybridization (FISH), and
              RNA-seq to obtain comprehensive three-dimensional (3D) maps of the
              Caenorhabditis elegans genome and to dissect X chromosome dosage
              compensation, which balances gene expression between XX
              hermaphrodites and XO males. The dosage compensation complex
              (DCC), a condensin complex, binds to both hermaphrodite X
              chromosomes via sequence-specific recruitment elements on X (rex
              sites) to reduce chromosome-wide gene expression by half. Most DCC
              condensin subunits also act in other condensin complexes to
              control the compaction and resolution of all mitotic and meiotic
              chromosomes. By comparing chromosome structure in wild-type and
              DCC-defective embryos, we show that the DCC remodels hermaphrodite
              X chromosomes into a sex-specific spatial conformation distinct
              from autosomes. Dosage-compensated X chromosomes consist of
              self-interacting domains (∼1 Mb) resembling mammalian
              topologically associating domains (TADs). TADs on X chromosomes
              have stronger boundaries and more regular spacing than on
              autosomes. Many TAD boundaries on X chromosomes coincide with the
              highest-affinity rex sites and become diminished or lost in
              DCC-defective mutants, thereby converting the topology of X to a
              conformation resembling autosomes. rex sites engage in
              DCC-dependent long-range interactions, with the most frequent
              interactions occurring between rex sites at DCC-dependent TAD
              boundaries. These results imply that the DCC reshapes the topology
              of X chromosomes by forming new TAD boundaries and reinforcing
              weak boundaries through interactions between its highest-affinity
              binding sites. As this model predicts, deletion of an endogenous
              rex site at a DCC-dependent TAD boundary using CRISPR/Cas9 greatly
              diminished the boundary. Thus, the DCC imposes a distinct
              higher-order structure onto X chromosomes while regulating gene
              expression chromosome-wide.",
  month    =  jul,
  year     =  2015,
  language = "en"
}

@ARTICLE{Schwarzer2017-as,
  title    = "Two independent modes of chromatin organization revealed by
              cohesin removal",
  author   = "Schwarzer, Wibke and Abdennur, Nezar and Goloborodko, Anton and
              Pekowska, Aleksandra and Fudenberg, Geoffrey and Loe-Mie, Yann and
              Fonseca, Nuno A and Huber, Wolfgang and Haering, Christian H and
              Mirny, Leonid and Spitz, Francois",
  journal  = "Nature",
  volume   =  551,
  number   =  7678,
  pages    = "51--56",
  abstract = "Imaging and chromosome conformation capture studies have revealed
              several layers of chromosome organization, including segregation
              into megabase-sized active and inactive compartments, and
              partitioning into sub-megabase domains (TADs). It remains unclear,
              however, how these layers of organization form, interact with one
              another and influence genome function. Here we show that deletion
              of the cohesin-loading factor Nipbl in mouse liver leads to a
              marked reorganization of chromosomal folding. TADs and associated
              Hi-C peaks vanish globally, even in the absence of transcriptional
              changes. By contrast, compartmental segregation is preserved and
              even reinforced. Strikingly, the disappearance of TADs unmasks a
              finer compartment structure that accurately reflects the
              underlying epigenetic landscape. These observations demonstrate
              that the three-dimensional organization of the genome results from
              the interplay of two independent mechanisms: cohesin-independent
              segregation of the genome into fine-scale compartments, defined by
              chromatin state; and cohesin-dependent formation of TADs, possibly
              by loop extrusion, which helps to guide distant enhancers to their
              target genes.",
  month    =  nov,
  year     =  2017,
  language = "en"
}

@ARTICLE{Butler2018-ej,
  title    = "Integrating single-cell transcriptomic data across different
              conditions, technologies, and species",
  author   = "Butler, Andrew and Hoffman, Paul and Smibert, Peter and Papalexi,
              Efthymia and Satija, Rahul",
  journal  = "Nat. Biotechnol.",
  volume   =  36,
  number   =  5,
  pages    = "411--420",
  abstract = "Computational single-cell RNA-seq (scRNA-seq) methods have been
              successfully applied to experiments representing a single
              condition, technology, or species to discover and define cellular
              phenotypes. However, identifying subpopulations of cells that are
              present across multiple data sets remains challenging. Here, we
              introduce an analytical strategy for integrating scRNA-seq data
              sets based on common sources of variation, enabling the
              identification of shared populations across data sets and
              downstream comparative analysis. We apply this approach,
              implemented in our R toolkit Seurat
              (http://satijalab.org/seurat/), to align scRNA-seq data sets of
              peripheral blood mononuclear cells under resting and stimulated
              conditions, hematopoietic progenitors sequenced using two
              profiling technologies, and pancreatic cell 'atlases' generated
              from human and mouse islets. In each case, we learn distinct or
              transitional cell states jointly across data sets, while boosting
              statistical power through integrated analysis. Our approach
              facilitates general comparisons of scRNA-seq data sets,
              potentially deepening our understanding of how distinct cell
              states respond to perturbation, disease, and evolution.",
  month    =  jun,
  year     =  2018,
  language = "en"
}

@ARTICLE{Imakaev2012-ih,
  title    = "Iterative correction of Hi-{C} data reveals hallmarks of
              chromosome organization",
  author   = "Imakaev, Maxim and Fudenberg, Geoffrey and McCord, Rachel Patton
              and Naumova, Natalia and Goloborodko, Anton and Lajoie, Bryan R
              and Dekker, Job and Mirny, Leonid A",
  journal  = "Nat. Methods",
  volume   =  9,
  number   =  10,
  pages    = "999--1003",
  abstract = "Extracting biologically meaningful information from chromosomal
              interactions obtained with genome-wide chromosome conformation
              capture (3C) analyses requires the elimination of systematic
              biases. We present a computational pipeline that integrates a
              strategy to map sequencing reads with a data-driven method for
              iterative correction of biases, yielding genome-wide maps of
              relative contact probabilities. We validate this ICE (iterative
              correction and eigenvector decomposition) technique on published
              data obtained by the high-throughput 3C method Hi-C, and we
              demonstrate that eigenvector decomposition of the obtained maps
              provides insights into local chromatin states, global patterns of
              chromosomal interactions, and the conserved organization of human
              and mouse chromosomes.",
  month    =  oct,
  year     =  2012,
  language = "en"
}

@ARTICLE{Ernst2017-vl,
  title    = "Chromatin-state discovery and genome annotation with {ChromHMM}",
  author   = "Ernst, Jason and Kellis, Manolis",
  journal  = "Nat. Protoc.",
  volume   =  12,
  number   =  12,
  pages    = "2478--2492",
  abstract = "Noncoding DNA regions have central roles in human biology,
              evolution, and disease. ChromHMM helps to annotate the noncoding
              genome using epigenomic information across one or multiple cell
              types. It combines multiple genome-wide epigenomic maps, and uses
              combinatorial and spatial mark patterns to infer a complete
              annotation for each cell type. ChromHMM learns chromatin-state
              signatures using a multivariate hidden Markov model (HMM) that
              explicitly models the combinatorial presence or absence of each
              mark. ChromHMM uses these signatures to generate a genome-wide
              annotation for each cell type by calculating the most probable
              state for each genomic segment. ChromHMM provides an automated
              enrichment analysis of the resulting annotations to facilitate the
              functional interpretations of each chromatin state. ChromHMM is
              distinguished by its modeling emphasis on combinations of marks,
              its tight integration with downstream functional enrichment
              analyses, its speed, and its ease of use. Chromatin states are
              learned, annotations are produced, and enrichments are computed
              within 1 d.",
  month    =  dec,
  year     =  2017,
  language = "en"
}

@ARTICLE{Xiong2019-fd,
  title    = "Revealing Hi-{C} subcompartments by imputing inter-chromosomal
              chromatin interactions",
  author   = "Xiong, Kyle and Ma, Jian",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    =  5069,
  abstract = "Higher-order genome organization and its variation in different
              cellular conditions remain poorly understood. Recent high-coverage
              genome-wide chromatin interaction mapping using Hi-C has revealed
              spatial segregation of chromosomes in the human genome into
              distinct subcompartments. However, subcompartment annotation,
              which requires Hi-C data with high sequencing coverage, is
              currently only available in the GM12878 cell line, making it
              impractical to compare subcompartment patterns across cell types.
              Here we develop a computational approach, SNIPER (Subcompartment
              iNference using Imputed Probabilistic ExpRessions), based on
              denoising autoencoder and multilayer perceptron classifier to
              infer subcompartments using typical Hi-C datasets with moderate
              coverage. SNIPER accurately reveals subcompartments using moderate
              coverage Hi-C datasets and outperforms an existing method that
              uses epigenomic features in GM12878. We apply SNIPER to eight
              additional cell lines and find that chromosomal regions with
              conserved and cell-type specific subcompartment annotations have
              different patterns of functional genomic features. SNIPER enables
              the identification of subcompartments without high-coverage Hi-C
              data and provides insights into the function and mechanisms of
              spatial genome organization variation across cell types.",
  month    =  nov,
  year     =  2019,
  language = "en"
}

@ARTICLE{Matthey-Doret2020-ly,
  title    = "Computer vision for pattern detection in chromosome contact maps",
  author   = "Matthey-Doret, Cyril and Baudry, Lyam and Breuer, Axel and
              Montagne, Rémi and Guiglielmoni, Nadège and Scolari, Vittore and
              Jean, Etienne and Campeas, Arnaud and Chanut, Philippe Henri and
              Oriol, Edgar and Méot, Adrien and Politis, Laurent and Vigouroux,
              Antoine and Moreau, Pierrick and Koszul, Romain and Cournac, Axel",
  journal  = "Nat. Commun.",
  volume   =  11,
  number   =  1,
  pages    =  5795,
  abstract = "Chromosomes of all species studied so far display a variety of
              higher-order organisational features, such as self-interacting
              domains or loops. These structures, which are often associated to
              biological functions, form distinct, visible patterns on
              genome-wide contact maps generated by chromosome conformation
              capture approaches such as Hi-C. Here we present Chromosight, an
              algorithm inspired from computer vision that can detect patterns
              in contact maps. Chromosight has greater sensitivity than existing
              methods on synthetic simulated data, while being faster and
              applicable to any type of genomes, including bacteria, viruses,
              yeasts and mammals. Our method does not require any prior training
              dataset and works well with default parameters on data generated
              with various protocols.",
  month    =  nov,
  year     =  2020,
  language = "en"
}

@ARTICLE{Liu2021-nc,
  title    = "Systematic inference and comparison of multi-scale chromatin
              sub-compartments connects spatial organization to cell phenotypes",
  author   = "Liu, Yuanlong and Nanni, Luca and Sungalee, Stephanie and
              Zufferey, Marie and Tavernari, Daniele and Mina, Marco and Ceri,
              Stefano and Oricchio, Elisa and Ciriello, Giovanni",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    =  2439,
  abstract = "Chromatin compartmentalization reflects biological activity.
              However, inference of chromatin sub-compartments and compartment
              domains from chromosome conformation capture (Hi-C) experiments is
              limited by data resolution. As a result, these have been
              characterized only in a few cell types and systematic comparisons
              across multiple tissues and conditions are missing. Here, we
              present Calder, an algorithmic approach that enables the
              identification of multi-scale sub-compartments at variable data
              resolution. Calder allows to infer and compare chromatin
              sub-compartments and compartment domains in >100 cell lines. Our
              results reveal sub-compartments enriched for poised chromatin
              states and undergoing spatial repositioning during lineage
              differentiation and oncogenic transformation.",
  month    =  may,
  year     =  2021,
  language = "en"
}

@ARTICLE{Sahin2021-gy,
  title    = "{HiC}-{DC+} enables systematic {3D} interaction calls and
              differential analysis for Hi-{C} and {HiChIP}",
  author   = "Sahin, Merve and Wong, Wilfred and Zhan, Yingqian and Van Deynze,
              Kinsey and Koche, Richard and Leslie, Christina S",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    =  3366,
  abstract = "Recent genome-wide chromosome conformation capture assays such as
              Hi-C and HiChIP have vastly expanded the resolution and throughput
              with which we can study 3D genomic architecture and function.
              Here, we present HiC-DC+, a software tool for Hi-C/HiChIP
              interaction calling and differential analysis using an efficient
              implementation of the HiC-DC statistical framework. HiC-DC+
              integrates with popular preprocessing and visualization tools and
              includes topologically associating domain (TAD) and A/B
              compartment callers. We found that HiC-DC+ can more accurately
              identify enhancer-promoter interactions in H3K27ac HiChIP, as
              validated by CRISPRi-FlowFISH experiments, compared to existing
              methods. Differential HiC-DC+ analyses of published HiChIP and
              Hi-C data sets in settings of cellular differentiation and cohesin
              perturbation systematically and quantitatively recovers biological
              findings, including enhancer hubs, TAD aggregation, and the
              relationship between promoter-enhancer loop dynamics and gene
              expression changes. HiC-DC+ therefore provides a principled
              statistical analysis tool to empower genome-wide studies of 3D
              chromatin architecture and function.",
  month    =  jun,
  year     =  2021,
  language = "en"
}

@ARTICLE{Shang2022-ju,
  title    = "Spatially aware dimension reduction for spatial transcriptomics",
  author   = "Shang, Lulu and Zhou, Xiang",
  journal  = "Nat. Commun.",
  volume   =  13,
  number   =  1,
  pages    =  7203,
  abstract = "Spatial transcriptomics are a collection of genomic technologies
              that have enabled transcriptomic profiling on tissues with spatial
              localization information. Analyzing spatial transcriptomic data is
              computationally challenging, as the data collected from various
              spatial transcriptomic technologies are often noisy and display
              substantial spatial correlation across tissue locations. Here, we
              develop a spatially-aware dimension reduction method, SpatialPCA,
              that can extract a low dimensional representation of the spatial
              transcriptomics data with biological signal and preserved spatial
              correlation structure, thus unlocking many existing computational
              tools previously developed in single-cell RNAseq studies for
              tailored analysis of spatial transcriptomics. We illustrate the
              benefits of SpatialPCA for spatial domain detection and explores
              its utility for trajectory inference on the tissue and for
              high-resolution spatial map construction. In the real data
              applications, SpatialPCA identifies key molecular and
              immunological signatures in a detected tumor surrounding
              microenvironment, including a tertiary lymphoid structure that
              shapes the gradual transcriptomic transition during tumorigenesis
              and metastasis. In addition, SpatialPCA detects the past neuronal
              developmental history that underlies the current transcriptomic
              landscape across tissue locations in the cortex.",
  month    =  nov,
  year     =  2022,
  language = "en"
}

@ARTICLE{Zuo2024-mj,
  title     = "Dissecting tumor microenvironment from spatially resolved
               transcriptomics data by heterogeneous graph learning",
  author    = "Zuo, Chunman and Xia, Junjie and Chen, Luonan",
  journal   = "Nat. Commun.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  15,
  number    =  1,
  pages     =  5057,
  abstract  = "Spatially resolved transcriptomics (SRT) has enabled precise
               dissection of tumor-microenvironment (TME) by analyzing its
               intracellular molecular networks and intercellular cell-cell
               communication (CCC). However, lacking computational exploration
               of complicated relations between cells, genes, and histological
               regions, severely limits the ability to interpret the complex
               structure of TME. Here, we introduce stKeep, a heterogeneous
               graph (HG) learning method that integrates multimodality and
               gene-gene interactions, in unraveling TME from SRT data. stKeep
               leverages HG to learn both cell-modules and gene-modules by
               incorporating features of diverse nodes including genes, cells,
               and histological regions, allows for identifying finer
               cell-states within TME and cell-state-specific gene-gene
               relations, respectively. Furthermore, stKeep employs HG to infer
               CCC for each cell, while ensuring that learned CCC patterns are
               comparable across different cell-states through contrastive
               learning. In various cancer samples, stKeep outperforms other
               tools in dissecting TME such as detecting bi-potent basal
               populations, neoplastic myoepithelial cells, and metastatic cells
               distributed within the tumor or leading-edge regions. Notably,
               stKeep identifies key transcription factors, ligands, and
               receptors relevant to disease progression, which are further
               validated by the functional and survival analysis of independent
               clinical data, thereby highlighting its clinical prognostic and
               immunotherapy applications.",
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Wu2022-cc,
  title     = "Graph deep learning for the characterization of tumour
               microenvironments from spatial protein profiles in tissue
               specimens",
  author    = "Wu, Zhenqin and Trevino, Alexandro E and Wu, Eric and Swanson,
               Kyle and Kim, Honesty J and D'Angio, H Blaize and Preska, Ryan
               and Charville, Gregory W and Dalerba, Piero D and Egloff, Ann
               Marie and Uppaluri, Ravindra and Duvvuri, Umamaheswar and Mayer,
               Aaron T and Zou, James",
  journal   = "Nat. Biomed. Eng.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  6,
  number    =  12,
  pages     = "1435--1448",
  abstract  = "Multiplexed immunofluorescence imaging allows the
               multidimensional molecular profiling of cellular environments at
               subcellular resolution. However, identifying and characterizing
               disease-relevant microenvironments from these rich datasets is
               challenging. Here we show that a graph neural network that
               leverages spatial protein profiles in tissue specimens to model
               tumour microenvironments as local subgraphs captures distinctive
               cellular interactions associated with differential clinical
               outcomes. We applied this spatial cellular-graph strategy to
               specimens of human head-and-neck and colorectal cancers assayed
               with 40-plex immunofluorescence imaging to identify spatial
               motifs associated with cancer recurrence and with patient
               survival after treatment. The graph deep learning model was
               substantially more accurate in predicting patient outcomes than
               deep learning approaches that model spatial data on the basis of
               the local composition of cell types, and it generated insights
               into the effect of the spatial compartmentalization of tumour
               cells and granulocytes on patient prognosis. Local graphs may
               also aid in the analysis of disease-relevant motifs in histology
               samples characterized via spatial transcriptomics and other
               -omics techniques.",
  month     =  dec,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Stickels2021-go,
  title    = "Highly sensitive spatial transcriptomics at near-cellular
              resolution with Slide-{seqV2}",
  author   = "Stickels, Robert R and Murray, Evan and Kumar, Pawan and Li,
              Jilong and Marshall, Jamie L and Di Bella, Daniela J and Arlotta,
              Paola and Macosko, Evan Z and Chen, Fei",
  journal  = "Nat. Biotechnol.",
  volume   =  39,
  number   =  3,
  pages    = "313--319",
  abstract = "Measurement of the location of molecules in tissues is essential
              for understanding tissue formation and function. Previously, we
              developed Slide-seq, a technology that enables transcriptome-wide
              detection of RNAs with a spatial resolution of 10 μm. Here we
              report Slide-seqV2, which combines improvements in library
              generation, bead synthesis and array indexing to reach an RNA
              capture efficiency ~50\% that of single-cell RNA-seq data
              (~10-fold greater than Slide-seq), approaching the detection
              efficiency of droplet-based single-cell RNA-seq techniques. First,
              we leverage the detection efficiency of Slide-seqV2 to identify
              dendritically localized mRNAs in neurons of the mouse hippocampus.
              Second, we integrate the spatial information of Slide-seqV2 data
              with single-cell trajectory analysis tools to characterize the
              spatiotemporal development of the mouse neocortex, identifying
              underlying genetic programs that were poorly sampled with
              Slide-seq. The combination of near-cellular resolution and high
              transcript detection efficiency makes Slide-seqV2 useful across
              many experimental contexts.",
  month    =  mar,
  year     =  2021,
  language = "en"
}

@ARTICLE{Cable2022-cv,
  title    = "Robust decomposition of cell type mixtures in spatial
              transcriptomics",
  author   = "Cable, Dylan M and Murray, Evan and Zou, Luli S and Goeva,
              Aleksandrina and Macosko, Evan Z and Chen, Fei and Irizarry,
              Rafael A",
  journal  = "Nat. Biotechnol.",
  volume   =  40,
  number   =  4,
  pages    = "517--526",
  abstract = "A limitation of spatial transcriptomics technologies is that
              individual measurements may contain contributions from multiple
              cells, hindering the discovery of cell-type-specific spatial
              patterns of localization and expression. Here, we develop robust
              cell type decomposition (RCTD), a computational method that
              leverages cell type profiles learned from single-cell RNA-seq to
              decompose cell type mixtures while correcting for differences
              across sequencing technologies. We demonstrate the ability of RCTD
              to detect mixtures and identify cell types on simulated datasets.
              Furthermore, RCTD accurately reproduces known cell type and
              subtype localization patterns in Slide-seq and Visium datasets of
              the mouse brain. Finally, we show how RCTD's recovery of cell type
              localization enables the discovery of genes within a cell type
              whose expression depends on spatial environment. Spatial mapping
              of cell types with RCTD enables the spatial components of cellular
              identity to be defined, uncovering new principles of cellular
              organization in biological tissue. RCTD is publicly available as
              an open-source R package at https://github.com/dmcable/RCTD .",
  month    =  apr,
  year     =  2022,
  language = "en"
}

@ARTICLE{Lohoff2022-ch,
  title     = "Integration of spatial and single-cell transcriptomic data
               elucidates mouse organogenesis",
  author    = "Lohoff, T and Ghazanfar, S and Missarova, A and Koulena, N and
               Pierson, N and Griffiths, J A and Bardot, E S and Eng, C-H L and
               Tyser, R C V and Argelaguet, R and Guibentif, C and Srinivas, S
               and Briscoe, J and Simons, B D and Hadjantonakis, A-K and
               Göttgens, B and Reik, W and Nichols, J and Cai, L and Marioni, J
               C",
  journal   = "Nat. Biotechnol.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  40,
  number    =  1,
  pages     = "74--85",
  abstract  = "Molecular profiling of single cells has advanced our knowledge of
               the molecular basis of development. However, current approaches
               mostly rely on dissociating cells from tissues, thereby losing
               the crucial spatial context of regulatory processes. Here, we
               apply an image-based single-cell transcriptomics method,
               sequential fluorescence in situ hybridization (seqFISH), to
               detect mRNAs for 387 target genes in tissue sections of mouse
               embryos at the 8-12 somite stage. By integrating spatial context
               and multiplexed transcriptional measurements with two single-cell
               transcriptome atlases, we characterize cell types across the
               embryo and demonstrate that spatially resolved expression of
               genes not profiled by seqFISH can be imputed. We use this
               high-resolution spatial map to characterize fundamental steps in
               the patterning of the midbrain-hindbrain boundary (MHB) and the
               developing gut tube. We uncover axes of cell differentiation that
               are not apparent from single-cell RNA-sequencing (scRNA-seq)
               data, such as early dorsal-ventral separation of esophageal and
               tracheal progenitor populations in the gut tube. Our method
               provides an approach for studying cell fate decisions in complex
               tissues and development.",
  month     =  jan,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Kleshchevnikov2022-kw,
  title     = "{Cell2location} maps fine-grained cell types in spatial
               transcriptomics",
  author    = "Kleshchevnikov, Vitalii and Shmatko, Artem and Dann, Emma and
               Aivazidis, Alexander and King, Hamish W and Li, Tong and
               Elmentaite, Rasa and Lomakin, Artem and Kedlian, Veronika and
               Gayoso, Adam and Jain, Mika Sarkin and Park, Jun Sung and Ramona,
               Lauma and Tuck, Elizabeth and Arutyunyan, Anna and Vento-Tormo,
               Roser and Gerstung, Moritz and James, Louisa and Stegle, Oliver
               and Bayraktar, Omer Ali",
  journal   = "Nat. Biotechnol.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  40,
  number    =  5,
  pages     = "661--671",
  abstract  = "Spatial transcriptomic technologies promise to resolve cellular
               wiring diagrams of tissues in health and disease, but
               comprehensive mapping of cell types in situ remains a challenge.
               Here we present сell2location, a Bayesian model that can resolve
               fine-grained cell types in spatial transcriptomic data and create
               comprehensive cellular maps of diverse tissues. Cell2location
               accounts for technical sources of variation and borrows
               statistical strength across locations, thereby enabling the
               integration of single-cell and spatial transcriptomics with
               higher sensitivity and resolution than existing tools. We
               assessed cell2location in three different tissues and show
               improved mapping of fine-grained cell types. In the mouse brain,
               we discovered fine regional astrocyte subtypes across the
               thalamus and hypothalamus. In the human lymph node, we spatially
               mapped a rare pre-germinal center B cell population. In the human
               gut, we resolved fine immune cell populations in lymphoid
               follicles. Collectively, our results present сell2location as a
               versatile analysis tool for mapping tissue architectures in a
               comprehensive manner.",
  month     =  may,
  year      =  2022,
  language  = "en"
}

@ARTICLE{He2025-td,
  title     = "Starfysh integrates spatial transcriptomic and histologic data to
               reveal heterogeneous tumor-immune hubs",
  author    = "He, Siyu and Jin, Yinuo and Nazaret, Achille and Shi, Lingting
               and Chen, Xueer and Rampersaud, Sham and Dhillon, Bahawar S and
               Valdez, Izabella and Friend, Lauren E and Fan, Joy Linyue and
               Park, Cameron Y and Mintz, Rachel L and Lao, Yeh-Hsing and
               Carrera, David and Fang, Kaylee W and Mehdi, Kaleem and Rohde,
               Madeline and McFaline-Figueroa, José L and Blei, David and Leong,
               Kam W and Rudensky, Alexander Y and Plitas, George and Azizi,
               Elham",
  journal   = "Nat. Biotechnol.",
  publisher = "Nature Publishing Group",
  volume    =  43,
  number    =  2,
  pages     = "223--235",
  abstract  = "Spatially resolved gene expression profiling provides insight
               into tissue organization and cell-cell crosstalk; however,
               sequencing-based spatial transcriptomics (ST) lacks single-cell
               resolution. Current ST analysis methods require single-cell RNA
               sequencing data as a reference for rigorous interpretation of
               cell states, mostly do not use associated histology images and
               are not capable of inferring shared neighborhoods across multiple
               tissues. Here we present Starfysh, a computational toolbox using
               a deep generative model that incorporates archetypal analysis and
               any known cell type markers to characterize known or new
               tissue-specific cell states without a single-cell reference.
               Starfysh improves the characterization of spatial dynamics in
               complex tissues using histology images and enables the comparison
               of niches as spatial hubs across tissues. Integrative analysis of
               primary estrogen receptor (ER)-positive breast cancer,
               triple-negative breast cancer (TNBC) and metaplastic breast
               cancer (MBC) tissues led to the identification of spatial hubs
               with patient- and disease-specific cell type compositions and
               revealed metabolic reprogramming shaping immunosuppressive hubs
               in aggressive MBC.",
  month     =  feb,
  year      =  2025,
  language  = "en"
}

@ARTICLE{Qian2020-an,
  title    = "Probabilistic cell typing enables fine mapping of closely related
              cell types in situ",
  author   = "Qian, Xiaoyan and Harris, Kenneth D and Hauling, Thomas and
              Nicoloutsopoulos, Dimitris and Muñoz-Manchado, Ana B and Skene,
              Nathan and Hjerling-Leffler, Jens and Nilsson, Mats",
  journal  = "Nat. Methods",
  volume   =  17,
  number   =  1,
  pages    = "101--106",
  abstract = "Understanding the function of a tissue requires knowing the
              spatial organization of its constituent cell types. In the
              cerebral cortex, single-cell RNA sequencing (scRNA-seq) has
              revealed the genome-wide expression patterns that define its many,
              closely related neuronal types, but cannot reveal their spatial
              arrangement. Here we introduce probabilistic cell typing by in
              situ sequencing (pciSeq), an approach that leverages previous
              scRNA-seq classification to identify cell types using multiplexed
              in situ RNA detection. We applied this method by mapping the
              inhibitory neurons of mouse hippocampal area CA1, for which ground
              truth is available from extensive previous work identifying their
              laminar organization. Our method identified these neuronal classes
              in a spatial arrangement matching ground truth, and further
              identified multiple classes of isocortical pyramidal cell in a
              pattern matching their known organization. This method will allow
              identifying the spatial organization of closely related cell types
              across the brain and other tissues.",
  month    =  jan,
  year     =  2020,
  language = "en"
}

@ARTICLE{Biancalani2021-jj,
  title     = "Deep learning and alignment of spatially resolved single-cell
               transcriptomes with Tangram",
  author    = "Biancalani, Tommaso and Scalia, Gabriele and Buffoni, Lorenzo and
               Avasthi, Raghav and Lu, Ziqing and Sanger, Aman and Tokcan,
               Neriman and Vanderburg, Charles R and Segerstolpe, Åsa and Zhang,
               Meng and Avraham-Davidi, Inbal and Vickovic, Sanja and Nitzan,
               Mor and Ma, Sai and Subramanian, Ayshwarya and Lipinski, Michal
               and Buenrostro, Jason and Brown, Nik Bear and Fanelli, Duccio and
               Zhuang, Xiaowei and Macosko, Evan Z and Regev, Aviv",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  18,
  number    =  11,
  pages     = "1352--1362",
  abstract  = "Charting an organs' biological atlas requires us to spatially
               resolve the entire single-cell transcriptome, and to relate such
               cellular features to the anatomical scale. Single-cell and
               single-nucleus RNA-seq (sc/snRNA-seq) can profile cells
               comprehensively, but lose spatial information. Spatial
               transcriptomics allows for spatial measurements, but at lower
               resolution and with limited sensitivity. Targeted in situ
               technologies solve both issues, but are limited in gene
               throughput. To overcome these limitations we present Tangram, a
               method that aligns sc/snRNA-seq data to various forms of spatial
               data collected from the same region, including MERFISH, STARmap,
               smFISH, Spatial Transcriptomics (Visium) and histological images.
               Tangram can map any type of sc/snRNA-seq data, including
               multimodal data such as those from SHARE-seq, which we used to
               reveal spatial patterns of chromatin accessibility. We
               demonstrate Tangram on healthy mouse brain tissue, by
               reconstructing a genome-wide anatomically integrated spatial map
               at single-cell resolution of the visual and somatomotor areas.",
  month     =  nov,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Velten2022-ci,
  title    = "Identifying temporal and spatial patterns of variation from
              multimodal data using {MEFISTO}",
  author   = "Velten, Britta and Braunger, Jana M and Argelaguet, Ricard and
              Arnol, Damien and Wirbel, Jakob and Bredikhin, Danila and Zeller,
              Georg and Stegle, Oliver",
  journal  = "Nat. Methods",
  volume   =  19,
  number   =  2,
  pages    = "179--186",
  abstract = "Factor analysis is a widely used method for dimensionality
              reduction in genome biology, with applications from personalized
              health to single-cell biology. Existing factor analysis models
              assume independence of the observed samples, an assumption that
              fails in spatio-temporal profiling studies. Here we present
              MEFISTO, a flexible and versatile toolbox for modeling
              high-dimensional data when spatial or temporal dependencies
              between the samples are known. MEFISTO maintains the established
              benefits of factor analysis for multimodal data, but enables the
              performance of spatio-temporally informed dimensionality
              reduction, interpolation, and separation of smooth from non-smooth
              patterns of variation. Moreover, MEFISTO can integrate multiple
              related datasets by simultaneously identifying and aligning the
              underlying patterns of variation in a data-driven manner. To
              illustrate MEFISTO, we apply the model to different datasets with
              spatial or temporal resolution, including an evolutionary atlas of
              organ development, a longitudinal microbiome study, a single-cell
              multi-omics atlas of mouse gastrulation and spatially resolved
              transcriptomics.",
  month    =  feb,
  year     =  2022,
  language = "en"
}

@ARTICLE{Velten2022-ws,
  title    = "Identifying temporal and spatial patterns of variation from
              multimodal data using {MEFISTO}",
  author   = "Velten, Britta and Braunger, Jana M and Argelaguet, Ricard and
              Arnol, Damien and Wirbel, Jakob and Bredikhin, Danila and Zeller,
              Georg and Stegle, Oliver",
  journal  = "Nat. Methods",
  volume   =  19,
  number   =  2,
  pages    = "179--186",
  abstract = "Factor analysis is a widely used method for dimensionality
              reduction in genome biology, with applications from personalized
              health to single-cell biology. Existing factor analysis models
              assume independence of the observed samples, an assumption that
              fails in spatio-temporal profiling studies. Here we present
              MEFISTO, a flexible and versatile toolbox for modeling
              high-dimensional data when spatial or temporal dependencies
              between the samples are known. MEFISTO maintains the established
              benefits of factor analysis for multimodal data, but enables the
              performance of spatio-temporally informed dimensionality
              reduction, interpolation, and separation of smooth from non-smooth
              patterns of variation. Moreover, MEFISTO can integrate multiple
              related datasets by simultaneously identifying and aligning the
              underlying patterns of variation in a data-driven manner. To
              illustrate MEFISTO, we apply the model to different datasets with
              spatial or temporal resolution, including an evolutionary atlas of
              organ development, a longitudinal microbiome study, a single-cell
              multi-omics atlas of mouse gastrulation and spatially resolved
              transcriptomics.",
  month    =  feb,
  year     =  2022,
  language = "en"
}

@ARTICLE{Velten2022-rc,
  title    = "Identifying temporal and spatial patterns of variation from
              multimodal data using {MEFISTO}",
  author   = "Velten, Britta and Braunger, Jana M and Argelaguet, Ricard and
              Arnol, Damien and Wirbel, Jakob and Bredikhin, Danila and Zeller,
              Georg and Stegle, Oliver",
  journal  = "Nat. Methods",
  volume   =  19,
  number   =  2,
  pages    = "179--186",
  abstract = "Factor analysis is a widely used method for dimensionality
              reduction in genome biology, with applications from personalized
              health to single-cell biology. Existing factor analysis models
              assume independence of the observed samples, an assumption that
              fails in spatio-temporal profiling studies. Here we present
              MEFISTO, a flexible and versatile toolbox for modeling
              high-dimensional data when spatial or temporal dependencies
              between the samples are known. MEFISTO maintains the established
              benefits of factor analysis for multimodal data, but enables the
              performance of spatio-temporally informed dimensionality
              reduction, interpolation, and separation of smooth from non-smooth
              patterns of variation. Moreover, MEFISTO can integrate multiple
              related datasets by simultaneously identifying and aligning the
              underlying patterns of variation in a data-driven manner. To
              illustrate MEFISTO, we apply the model to different datasets with
              spatial or temporal resolution, including an evolutionary atlas of
              organ development, a longitudinal microbiome study, a single-cell
              multi-omics atlas of mouse gastrulation and spatially resolved
              transcriptomics.",
  month    =  feb,
  year     =  2022,
  language = "en"
}

@ARTICLE{Palla2022-xf,
  title    = "Squidpy: a scalable framework for spatial omics analysis",
  author   = "Palla, Giovanni and Spitzer, Hannah and Klein, Michal and Fischer,
              David and Schaar, Anna Christina and Kuemmerle, Louis Benedikt and
              Rybakov, Sergei and Ibarra, Ignacio L and Holmberg, Olle and
              Virshup, Isaac and Lotfollahi, Mohammad and Richter, Sabrina and
              Theis, Fabian J",
  journal  = "Nat. Methods",
  volume   =  19,
  number   =  2,
  pages    = "171--178",
  abstract = "Spatial omics data are advancing the study of tissue organization
              and cellular communication at an unprecedented scale. Flexible
              tools are required to store, integrate and visualize the large
              diversity of spatial omics data. Here, we present Squidpy, a
              Python framework that brings together tools from omics and image
              analysis to enable scalable description of spatial molecular data,
              such as transcriptome or multivariate proteins. Squidpy provides
              efficient infrastructure and numerous analysis methods that allow
              to efficiently store, manipulate and interactively visualize
              spatial omics data. Squidpy is extensible and can be interfaced
              with a variety of already existing libraries for the scalable
              analysis of spatial omics data.",
  month    =  feb,
  year     =  2022,
  language = "en"
}

@ARTICLE{Moses2022-sw,
  title    = "Museum of spatial transcriptomics",
  author   = "Moses, Lambda and Pachter, Lior",
  journal  = "Nat. Methods",
  volume   =  19,
  number   =  5,
  pages    = "534--546",
  abstract = "The function of many biological systems, such as embryos, liver
              lobules, intestinal villi, and tumors, depends on the spatial
              organization of their cells. In the past decade, high-throughput
              technologies have been developed to quantify gene expression in
              space, and computational methods have been developed that leverage
              spatial gene expression data to identify genes with spatial
              patterns and to delineate neighborhoods within tissues. To
              comprehensively document spatial gene expression technologies and
              data-analysis methods, we present a curated review of literature
              on spatial transcriptomics dating back to 1987, along with a
              thorough analysis of trends in the field, such as usage of
              experimental techniques, species, tissues studied, and
              computational approaches used. Our Review places current methods
              in a historical context, and we derive insights about the field
              that can guide current research strategies. A companion supplement
              offers a more detailed look at the technologies and methods
              analyzed: https://pachterlab.github.io/LP\_2021/ .",
  month    =  may,
  year     =  2022,
  language = "en"
}

@ARTICLE{Townes2023-it,
  title    = "Nonnegative spatial factorization applied to spatial genomics",
  author   = "Townes, F William and Engelhardt, Barbara E",
  journal  = "Nat. Methods",
  volume   =  20,
  number   =  2,
  pages    = "229--238",
  abstract = "Nonnegative matrix factorization (NMF) is widely used to analyze
              high-dimensional count data because, in contrast to real-valued
              alternatives such as factor analysis, it produces an interpretable
              parts-based representation. However, in applications such as
              spatial transcriptomics, NMF fails to incorporate known structure
              between observations. Here, we present nonnegative spatial
              factorization (NSF), a spatially-aware probabilistic dimension
              reduction model based on transformed Gaussian processes that
              naturally encourages sparsity and scales to tens of thousands of
              observations. NSF recovers ground truth factors more accurately
              than real-valued alternatives such as MEFISTO in simulations, and
              has lower out-of-sample prediction error than probabilistic NMF on
              three spatial transcriptomics datasets from mouse brain and liver.
              Since not all patterns of gene expression have spatial
              correlations, we also propose a hybrid extension of NSF that
              combines spatial and nonspatial components, enabling
              quantification of spatial importance for both observations and
              features. A TensorFlow implementation of NSF is available from
              https://github.com/willtownes/nsf-paper .",
  month    =  feb,
  year     =  2023,
  language = "en"
}

@ARTICLE{Hallou2025-sw,
  title     = "A computational pipeline for spatial mechano-transcriptomics",
  author    = "Hallou, Adrien and He, Ruiyang and Simons, Benjamin D and
               Dumitrascu, Bianca",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  22,
  number    =  4,
  pages     = "737--750",
  abstract  = "Advances in spatial profiling technologies are providing insights
               into how molecular programs are influenced by local signaling and
               environmental cues. However, cell fate specification and tissue
               patterning involve the interplay of biochemical and mechanical
               feedback. Here we develop a computational framework that enables
               the joint statistical analysis of transcriptional and mechanical
               signals in the context of spatial transcriptomics. To illustrate
               the application and utility of the approach, we use spatial
               transcriptomics data from the developing mouse embryo to infer
               the forces acting on individual cells, and use these results to
               identify mechanical, morphometric and gene expression signatures
               that are predictive of tissue compartment boundaries. In
               addition, we use geoadditive structural equation modeling to
               identify gene modules that predict the mechanical behavior of
               cells in an unbiased manner. This computational framework is
               easily generalized to other spatial profiling contexts, providing
               a generic scheme for exploring the interplay of biomolecular and
               mechanical cues in tissues.",
  month     =  apr,
  year      =  2025,
  language  = "en"
}

@ARTICLE{Wiltschko2020-ge,
  title    = "Revealing the structure of pharmacobehavioral space through motion
              sequencing",
  author   = "Wiltschko, Alexander B and Tsukahara, Tatsuya and Zeine, Ayman and
              Anyoha, Rockwell and Gillis, Winthrop F and Markowitz, Jeffrey E
              and Peterson, Ralph E and Katon, Jesse and Johnson, Matthew J and
              Datta, Sandeep Robert",
  journal  = "Nat. Neurosci.",
  volume   =  23,
  number   =  11,
  pages    = "1433--1443",
  abstract = "Understanding how genes, drugs and neural circuits influence
              behavior requires the ability to effectively organize information
              about similarities and differences within complex behavioral
              datasets. Motion Sequencing (MoSeq) is an ethologically inspired
              behavioral analysis method that identifies modular components of
              three-dimensional mouse body language called 'syllables'. Here, we
              show that MoSeq effectively parses behavioral differences and
              captures similarities elicited by a panel of neuroactive and
              psychoactive drugs administered to a cohort of nearly 700 mice.
              MoSeq identifies syllables that are characteristic of individual
              drugs, a finding we leverage to reveal specific on- and off-target
              effects of both established and candidate therapeutics in a mouse
              model of autism spectrum disorder. These results demonstrate that
              MoSeq can meaningfully organize large-scale behavioral data,
              illustrate the power of a fundamentally modular description of
              behavior and suggest that behavioral syllables represent a new
              class of druggable target.",
  month    =  nov,
  year     =  2020,
  language = "en"
}

@ARTICLE{Spracklin2023-br,
  title    = "Diverse silent chromatin states modulate genome
              compartmentalization and loop extrusion barriers",
  author   = "Spracklin, George and Abdennur, Nezar and Imakaev, Maxim and
              Chowdhury, Neil and Pradhan, Sriharsa and Mirny, Leonid A and
              Dekker, Job",
  journal  = "Nat. Struct. Mol. Biol.",
  volume   =  30,
  number   =  1,
  pages    = "38--51",
  abstract = "The relationships between chromosomal compartmentalization,
              chromatin state and function are poorly understood. Here by
              profiling long-range contact frequencies in HCT116 colon cancer
              cells, we distinguish three silent chromatin states, comprising
              two types of heterochromatin and a state enriched for H3K9me2 and
              H2A.Z that exhibits neutral three-dimensional interaction
              preferences and which, to our knowledge, has not previously been
              characterized. We find that heterochromatin marked by H3K9me3,
              HP1α and HP1β correlates with strong compartmentalization. We
              demonstrate that disruption of DNA methyltransferase activity
              greatly remodels genome compartmentalization whereby domains lose
              H3K9me3-HP1α/β binding and acquire the neutrally interacting state
              while retaining late replication timing. Furthermore, we show that
              H3K9me3-HP1α/β heterochromatin is permissive to loop extrusion by
              cohesin but refractory to CTCF binding. Together, our work reveals
              a dynamic structural and organizational diversity of the silent
              portion of the genome and establishes connections between the
              regulation of chromatin state and chromosome organization,
              including an interplay between DNA methylation,
              compartmentalization and loop extrusion.",
  month    =  jan,
  year     =  2023,
  language = "en"
}

@ARTICLE{Nuebler2018-mz,
  title    = "Chromatin organization by an interplay of loop extrusion and
              compartmental segregation",
  author   = "Nuebler, Johannes and Fudenberg, Geoffrey and Imakaev, Maxim and
              Abdennur, Nezar and Mirny, Leonid A",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  115,
  number   =  29,
  pages    = "E6697--E6706",
  abstract = "Mammalian chromatin is spatially organized at many scales showing
              two prominent features in interphase: (i) alternating regions
              (1-10 Mb) of active and inactive chromatin that spatially
              segregate into different compartments, and (ii) domains (<1 Mb),
              that is, regions that preferentially interact internally
              [topologically associating domains (TADs)] and are central to gene
              regulation. There is growing evidence that TADs are formed by
              active extrusion of chromatin loops by cohesin, whereas
              compartmentalization is established according to local chromatin
              states. Here, we use polymer simulations to examine how loop
              extrusion and compartmental segregation work collectively and
              potentially interfere in shaping global chromosome organization. A
              model with differential attraction between euchromatin and
              heterochromatin leads to phase separation and reproduces
              compartmentalization as observed in Hi-C. Loop extrusion,
              essential for TAD formation, in turn, interferes with
              compartmentalization. Our integrated model faithfully reproduces
              Hi-C data from puzzling experimental observations where altering
              loop extrusion also led to changes in compartmentalization.
              Specifically, depletion of chromatin-associated cohesin reduced
              TADs and revealed finer compartments, while increased processivity
              of cohesin strengthened large TADs and reduced
              compartmentalization; and depletion of the TAD boundary protein
              CTCF weakened TADs while leaving compartments unaffected. We
              reveal that these experimental perturbations are special cases of
              a general polymer phenomenon of active mixing by loop extrusion.
              Our results suggest that chromatin organization on the megabase
              scale emerges from competition of nonequilibrium active loop
              extrusion and epigenetically defined compartment structure.",
  month    =  jul,
  year     =  2018,
  keywords = "Hi-C; active matter; chromatin; genome architecture; polymer
              physics",
  language = "en"
}

@ARTICLE{Sandholtz2020-vk,
  title    = "Physical modeling of the heritability and maintenance of
              epigenetic modifications",
  author   = "Sandholtz, Sarah H and MacPherson, Quinn and Spakowitz, Andrew J",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  34,
  pages    = "20423--20429",
  abstract = "We develop a predictive theoretical model of the physical
              mechanisms that govern the heritability and maintenance of
              epigenetic modifications. This model focuses on a particular
              modification, methylation of lysine-9 of histone H3 (H3K9), which
              is one of the most representative and critical epigenetic marks
              that affects chromatin organization and gene expression. Our model
              combines the effect of segregation and compaction on chromosomal
              organization with the effect of the interaction between proteins
              that compact the chromatin (heterochromatin protein 1) and the
              methyltransferases that affect methyl spreading. Our chromatin
              model demonstrates that a block of H3K9 methylations in the
              epigenetic sequence determines the compaction state at any
              particular location in the chromatin. Using our predictive model
              for chromatin compaction, we develop a methylation model to
              address the reestablishment of the methylation sequence following
              DNA replication. Our model reliably maintains methylation over
              generations, thereby establishing the robustness of the epigenetic
              code.",
  month    =  aug,
  year     =  2020,
  keywords = "Monte Carlo simulations; chromosome modeling; epigenetics; genome
              organization; heritability",
  language = "en"
}

@ARTICLE{Verma2021-sj,
  title    = "A self-exciting point process to study multicellular spatial
              signaling patterns",
  author   = "Verma, Archit and Jena, Siddhartha G and Isakov, Danielle R and
              Aoki, Kazuhiro and Toettcher, Jared E and Engelhardt, Barbara E",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  118,
  number   =  32,
  abstract = "Multicellular organisms rely on spatial signaling among cells to
              drive their organization, development, and response to stimuli.
              Several models have been proposed to capture the behavior of
              spatial signaling in multicellular systems, but existing
              approaches fail to capture both the autonomous behavior of single
              cells and the interactions of a cell with its neighbors
              simultaneously. We propose a spatiotemporal model of dynamic cell
              signaling based on Hawkes processes-self-exciting point
              processes-that model the signaling processes within a cell and
              spatial couplings between cells. With this cellular point process
              (CPP), we capture both the single-cell pathway activation rate and
              the magnitude and duration of signaling between cells relative to
              their spatial location. Furthermore, our model captures tissues
              composed of heterogeneous cell types with different bursting rates
              and signaling behaviors across multiple signaling proteins. We
              apply our model to epithelial cell systems that exhibit a range of
              autonomous and spatial signaling behaviors basally and under
              pharmacological exposure. Our model identifies known drug-induced
              signaling deficits, characterizes signaling changes across a wound
              front, and generalizes to multichannel observations.",
  month    =  aug,
  year     =  2021,
  keywords = "Hawkes process; cell signaling; keratinocytes; kinase networks;
              point process",
  language = "en"
}

@ARTICLE{Ogawa1990-mq,
  title     = "Brain magnetic resonance imaging with contrast dependent on blood
               oxygenation",
  author    = "Ogawa, S and Lee, T M and Kay, A R and Tank, D W",
  journal   = "Proc. Natl. Acad. Sci. U. S. A.",
  publisher = "Proceedings of the National Academy of Sciences",
  volume    =  87,
  number    =  24,
  pages     = "9868--9872",
  abstract  = "Paramagnetic deoxyhemoglobin in venous blood is a naturally
               occurring contrast agent for magnetic resonance imaging (MRI). By
               accentuating the effects of this agent through the use of
               gradient-echo techniques in high fields, we demonstrate in vivo
               images of brain microvasculature with image contrast reflecting
               the blood oxygen level. This blood oxygenation level-dependent
               (BOLD) contrast follows blood oxygen changes induced by
               anesthetics, by insulin-induced hypoglycemia, and by inhaled gas
               mixtures that alter metabolic demand or blood flow. The results
               suggest that BOLD contrast can be used to provide in vivo
               real-time maps of blood oxygenation in the brain under normal
               physiological conditions. BOLD contrast adds an additional
               feature to magnetic resonance imaging and complements other
               techniques that are attempting to provide positron emission
               tomography-like measurements related to regional neural activity.",
  month     =  dec,
  year      =  1990,
  language  = "en"
}

@ARTICLE{Blei2017-zr,
  title     = "Variational Inference: A Review for Statisticians",
  author    = "Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  112,
  number    =  518,
  pages     = "859--877",
  abstract  = "ABSTRACTOne of the core problems of modern statistics is to
               approximate difficult-to-compute probability densities. This
               problem is especially important in Bayesian statistics, which
               frames all inference about unknown quantities as a calculation
               involving the posterior density. In this article, we review
               variational inference (VI), a method from machine learning that
               approximates probability densities through optimization. VI has
               been used in many applications and tends to be faster than
               classical methods, such as Markov chain Monte Carlo sampling. The
               idea behind VI is to first posit a family of densities and then
               to find a member of that family which is close to the target
               density. Closeness is measured by Kullback?Leibler divergence. We
               review the ideas behind mean-field variational inference, discuss
               the special case of VI applied to exponential family models,
               present a full example with a Bayesian mixture of Gaussians, and
               derive a variant that uses stochastic optimization to scale up to
               massive data. We discuss modern research in VI and highlight
               important open problems. VI is powerful, but it is not yet well
               understood. Our hope in writing this article is to catalyze
               statistical research on this class of algorithms. Supplementary
               materials for this article are available online.",
  month     =  apr,
  year      =  2017
}

@ARTICLE{Blei2017-ed,
  title     = "Variational Inference: A Review for Statisticians",
  author    = "Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  112,
  number    =  518,
  pages     = "859--877",
  abstract  = "ABSTRACTOne of the core problems of modern statistics is to
               approximate difficult-to-compute probability densities. This
               problem is especially important in Bayesian statistics, which
               frames all inference about unknown quantities as a calculation
               involving the posterior density. In this article, we review
               variational inference (VI), a method from machine learning that
               approximates probability densities through optimization. VI has
               been used in many applications and tends to be faster than
               classical methods, such as Markov chain Monte Carlo sampling. The
               idea behind VI is to first posit a family of densities and then
               to find a member of that family which is close to the target
               density. Closeness is measured by Kullback?Leibler divergence. We
               review the ideas behind mean-field variational inference, discuss
               the special case of VI applied to exponential family models,
               present a full example with a Bayesian mixture of Gaussians, and
               derive a variant that uses stochastic optimization to scale up to
               massive data. We discuss modern research in VI and highlight
               important open problems. VI is powerful, but it is not yet well
               understood. Our hope in writing this article is to catalyze
               statistical research on this class of algorithms. Supplementary
               materials for this article are available online.",
  month     =  apr,
  year      =  2017
}

@ARTICLE{Walter2023-kz,
  title    = "{FISHFactor}: a probabilistic factor model for spatial
              transcriptomics data with subcellular resolution",
  author   = "Walter, Florin C and Stegle, Oliver and Velten, Britta",
  journal  = "Bioinformatics",
  volume   =  39,
  number   =  4,
  abstract = "MOTIVATION: Factor analysis is a widely used tool for unsupervised
              dimensionality reduction of high-throughput datasets in molecular
              biology, with recently proposed extensions designed specifically
              for spatial transcriptomics data. However, these methods expect
              (count) matrices as data input and are therefore not directly
              applicable to single molecule resolution data, which are in the
              form of coordinate lists annotated with genes and provide insight
              into subcellular spatial expression patterns. To address this, we
              here propose FISHFactor, a probabilistic factor model that
              combines the benefits of spatial, non-negative factor analysis
              with a Poisson point process likelihood to explicitly model and
              account for the nature of single molecule resolution data. In
              addition, FISHFactor shares information across a potentially large
              number of cells in a common weight matrix, allowing consistent
              interpretation of factors across cells and yielding improved
              latent variable estimates. RESULTS: We compare FISHFactor to
              existing methods that rely on aggregating information through
              spatial binning and cannot combine information from multiple cells
              and show that our method leads to more accurate results on
              simulated data. We show that our method is scalable and can be
              readily applied to large datasets. Finally, we demonstrate on a
              real dataset that FISHFactor is able to identify major subcellular
              expression patterns and spatial gene clusters in a data-driven
              manner. AVAILABILITY AND IMPLEMENTATION: The model implementation,
              data simulation and experiment scripts are available under
              https://www.github.com/bioFAM/FISHFactor.",
  month    =  may,
  year     =  2023,
  language = "en"
}

@ARTICLE{Weinreb2016-gn,
  title    = "Identification of hierarchical chromatin domains",
  author   = "Weinreb, Caleb and Raphael, Benjamin J",
  journal  = "Bioinformatics",
  volume   =  32,
  number   =  11,
  pages    = "1601--1609",
  abstract = "MOTIVATION: The three-dimensional structure of the genome is an
              important regulator of many cellular processes including
              differentiation and gene regulation. Recently, technologies such
              as Hi-C that combine proximity ligation with high-throughput
              sequencing have revealed domains of self-interacting chromatin,
              called topologically associating domains (TADs), in many
              organisms. Current methods for identifying TADs using Hi-C data
              assume that TADs are non-overlapping, despite evidence for a
              nested structure in which TADs and sub-TADs form a complex
              hierarchy. RESULTS: We introduce a model for decomposition of
              contact frequencies into a hierarchy of nested TADs. This model is
              based on empirical distributions of contact frequencies within
              TADs, where positions that are far apart have a greater enrichment
              of contacts than positions that are close together. We find that
              the increase in contact enrichment with distance is stronger for
              the inner TAD than for the outer TAD in a TAD/sub-TAD pair. Using
              this model, we develop the TADtree algorithm for detecting
              hierarchies of nested TADs. TADtree compares favorably with
              previous methods, finding TADs with a greater enrichment of
              chromatin marks such as CTCF at their boundaries. AVAILABILITY AND
              IMPLEMENTATION: A python implementation of TADtree is available at
              http://compbio.cs.brown.edu/software/ CONTACT:
              braphael@cs.brown.edu SUPPLEMENTARY INFORMATION: Supplementary
              data are available at Bioinformatics online.",
  month    =  jun,
  year     =  2016,
  language = "en"
}

@ARTICLE{Elosua-Bayes2021-aw,
  title    = "{SPOTlight}: seeded {NMF} regression to deconvolute spatial
              transcriptomics spots with single-cell transcriptomes",
  author   = "Elosua-Bayes, Marc and Nieto, Paula and Mereu, Elisabetta and Gut,
              Ivo and Heyn, Holger",
  journal  = "Nucleic Acids Res.",
  volume   =  49,
  number   =  9,
  pages    = "e50",
  abstract = "Spatially resolved gene expression profiles are key to understand
              tissue organization and function. However, spatial transcriptomics
              (ST) profiling techniques lack single-cell resolution and require
              a combination with single-cell RNA sequencing (scRNA-seq)
              information to deconvolute the spatially indexed datasets.
              Leveraging the strengths of both data types, we developed
              SPOTlight, a computational tool that enables the integration of ST
              with scRNA-seq data to infer the location of cell types and states
              within a complex tissue. SPOTlight is centered around a seeded
              non-negative matrix factorization (NMF) regression, initialized
              using cell-type marker genes and non-negative least squares (NNLS)
              to subsequently deconvolute ST capture locations (spots).
              Simulating varying reference quantities and qualities, we
              confirmed high prediction accuracy also with shallowly sequenced
              or small-sized scRNA-seq reference datasets. SPOTlight
              deconvolution of the mouse brain correctly mapped subtle neuronal
              cell states of the cortical layers and the defined architecture of
              the hippocampus. In human pancreatic cancer, we successfully
              segmented patient sections and further fine-mapped normal and
              neoplastic cell states. Trained on an external single-cell
              pancreatic tumor references, we further charted the localization
              of clinical-relevant and tumor-specific immune cell states, an
              illustrative example of its flexible application spectrum and
              future potential in digital pathology.",
  month    =  may,
  year     =  2021,
  language = "en"
}

@ARTICLE{Costacurta2022-nn,
  title    = "Distinguishing discrete and continuous behavioral variability
              using warped autoregressive {HMMs}",
  author   = "Costacurta, Julia C and Duncker, Lea and Sheffer, Blue and Gillis,
              Winthrop and Weinreb, Caleb and Markowitz, Jeffrey E and Datta,
              Sandeep R and Williams, Alex H and Linderman, Scott W",
  journal  = "bioRxiv",
  abstract = "AbstractA core goal in systems neuroscience and neuroethology is
              to understand how neural circuits generate naturalistic behavior.
              One foundational idea is that complex naturalistic behavior may be
              composed of sequences of stereotyped behavioral syllables, which
              combine to generate rich sequences of actions. To investigate
              this, a common approach is to use autoregressive hidden Markov
              models (ARHMMs) to segment video into discrete behavioral
              syllables. While these approaches have been successful in
              extracting syllables that are interpretable, they fail to account
              for other forms of behavioral variability, such as differences in
              speed, which may be better described as continuous in nature. To
              overcome these limitations, we introduce a class of warped ARHMMs
              (WARHMM). As is the case in the ARHMM, behavior is modeled as a
              mixture of autoregressive dynamics. However, the dynamics under
              each discrete latent state (i.e. each behavioral syllable) are
              additionally modulated by a continuous latent “warping variable.”
              We present two versions of warped ARHMM in which the warping
              variable affects the dynamics of each syllable either linearly or
              nonlinearly. Using depth-camera recordings of freely moving mice,
              we demonstrate that the failure of ARHMMs to account for
              continuous behavioral variability results in duplicate cluster
              assignments. WARHMM achieves similar performance to the standard
              ARHMM while using fewer behavioral syllables. Further analysis of
              behavioral measurements in mice demonstrates that WARHMM
              identifies structure relating to response vigor.",
  month    =  jun,
  year     =  2022
}

@ARTICLE{Tipping1999-gd,
  title     = "Probabilistic principal component analysis",
  author    = "Tipping, Michael E and Bishop, Christopher M",
  journal   = "J. R. Stat. Soc. Series B Stat. Methodol.",
  publisher = "Oxford University Press (OUP)",
  volume    =  61,
  number    =  3,
  pages     = "611--622",
  abstract  = "Principal component analysis (PCA) is a ubiquitous technique for
               data analysis and processing, but one which is not based upon a
               probability model. In this paper we demonstrate how the principal
               axes of a set of observed data vectors may be determined through
               maximum-likelihood estimation of parameters in a latent variable
               model closely related to factor analysis. We consider the
               properties of the associated likelihood function, giving an EM
               algorithm for estimating the principal subspace iteratively, and
               discuss the advantages conveyed by the definition of a
               probability density function for PCA.",
  month     =  aug,
  year      =  1999,
  language  = "en"
}

@ARTICLE{Diggle1998-xz,
  title     = "Model-based geostatistics",
  author    = "Diggle, P J and Tawn, J A and Moyeed, R A",
  journal   = "J. R. Stat. Soc. Ser. C. Appl. Stat.",
  publisher = "Oxford University Press (OUP)",
  volume    =  47,
  number    =  3,
  pages     = "299--350",
  abstract  = "SUMMARY Conventional geostatistical methodology solves the
               problem of predicting the realized value of a linear functional
               of a Gaussian spatial stochastic process S(x) based on
               observations Yi = S(xi) + Zi at sampling locations xi, where the
               Zi are mutually independent, zero-mean Gaussian random variables.
               We describe two spatial applications for which Gaussian
               distributional assumptions are clearly inappropriate. The first
               concerns the assessment of residual contamination from nuclear
               weapons testing on a South Pacific island, in which the sampling
               method generates spatially indexed Poisson counts conditional on
               an unobserved spatially varying intensity of radioactivity; we
               conclude that a conventional geostatistical analysis oversmooths
               the data and underestimates the spatial extremes of the
               intensity. The second application provides a description of
               spatial variation in the risk of campylobacter infections
               relative to other enteric infections in part of north Lancashire
               and south Cumbria. For this application, we treat the data as
               binomial counts at unit postcode locations, conditionally on an
               unobserved relative risk surface which we estimate. The
               theoretical framework for our extension of geostatistical methods
               is that, conditionally on the unobserved process S(x),
               observations at sample locations xi form a generalized linear
               model with the corresponding values of S(xi) appearing as an
               offset term in the linear predictor. We use a Bayesian
               inferential framework, implemented via the Markov chain Monte
               Carlo method, to solve the prediction problem for non-linear
               functionals of S(x), making a proper allowance for the
               uncertainty in the estimation of any model parameters.",
  month     =  sep,
  year      =  1998,
  language  = "en"
}

@ARTICLE{Szabo2019-nu,
  title    = "Principles of genome folding into topologically associating
              domains",
  author   = "Szabo, Quentin and Bantignies, Frédéric and Cavalli, Giacomo",
  journal  = "Sci Adv",
  volume   =  5,
  number   =  4,
  pages    = "eaaw1668",
  abstract = "Understanding the mechanisms that underlie chromosome folding
              within cell nuclei is essential to determine the relationship
              between genome structure and function. The recent application of
              ``chromosome conformation capture'' techniques has revealed that
              the genome of many species is organized into domains of
              preferential internal chromatin interactions called
              ``topologically associating domains'' (TADs). This chromosome
              chromosome folding has emerged as a key feature of higher-order
              genome organization and function through evolution. Although TADs
              have now been described in a wide range of organisms, they appear
              to have specific characteristics in terms of size, structure, and
              proteins involved in their formation. Here, we depict the main
              features of these domains across species and discuss the relation
              between chromatin structure, genome activity, and epigenome,
              highlighting mechanistic principles of TAD formation. We also
              consider the potential influence of TADs in genome evolution.",
  month    =  apr,
  year     =  2019,
  language = "en"
}

@ARTICLE{Zhang2024-wz,
  title     = "{SpaTopic}: A statistical learning framework for exploring tumor
               spatial architecture from spatially resolved transcriptomic data",
  author    = "Zhang, Yuelei and Yu, Bianjiong and Ming, Wenxuan and Zhou,
               Xiaolong and Wang, Jin and Chen, Dijun",
  journal   = "Sci. Adv.",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  10,
  number    =  39,
  pages     = "eadp4942",
  abstract  = "Tumor tissues exhibit a complex spatial architecture within the
               tumor microenvironment (TME). Spatially resolved transcriptomics
               (SRT) is promising for unveiling the spatial structures of the
               TME at both cellular and molecular levels, but identifying
               pathology-relevant spatial domains remains challenging. Here, we
               introduce SpaTopic, a statistical learning framework that
               harmonizes spot clustering and cell-type deconvolution by
               integrating single-cell transcriptomics and SRT data. Through
               topic modeling, SpaTopic stratifies the TME into spatial domains
               with coherent cellular organization, facilitating refined
               annotation of the spatial architecture with improved performance.
               We assess SpaTopic across various tumor types and show accurate
               prediction of tertiary lymphoid structures and tumor boundaries.
               Moreover, marker genes derived from SpaTopic are transferrable
               and can be applied to mark spatial domains in other datasets. In
               addition, SpaTopic enables quantitative comparison and functional
               characterization of spatial domains across SRT datasets. Overall,
               SpaTopic presents an innovative analytical framework for
               exploring, comparing, and interpreting tumor SRT data.",
  month     =  sep,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Lieberman-Aiden2009-cu,
  title    = "Comprehensive mapping of long-range interactions reveals folding
              principles of the human genome",
  author   = "Lieberman-Aiden, Erez and van Berkum, Nynke L and Williams, Louise
              and Imakaev, Maxim and Ragoczy, Tobias and Telling, Agnes and
              Amit, Ido and Lajoie, Bryan R and Sabo, Peter J and Dorschner,
              Michael O and Sandstrom, Richard and Bernstein, Bradley and
              Bender, M A and Groudine, Mark and Gnirke, Andreas and
              Stamatoyannopoulos, John and Mirny, Leonid A and Lander, Eric S
              and Dekker, Job",
  journal  = "Science",
  volume   =  326,
  number   =  5950,
  pages    = "289--293",
  abstract = "We describe Hi-C, a method that probes the three-dimensional
              architecture of whole genomes by coupling proximity-based ligation
              with massively parallel sequencing. We constructed spatial
              proximity maps of the human genome with Hi-C at a resolution of 1
              megabase. These maps confirm the presence of chromosome
              territories and the spatial proximity of small, gene-rich
              chromosomes. We identified an additional level of genome
              organization that is characterized by the spatial segregation of
              open and closed chromatin to form two genome-wide compartments. At
              the megabase scale, the chromatin conformation is consistent with
              a fractal globule, a knot-free, polymer conformation that enables
              maximally dense packing while preserving the ability to easily
              fold and unfold any genomic locus. The fractal globule is distinct
              from the more commonly used globular equilibrium model. Our
              results demonstrate the power of Hi-C to map the dynamic
              conformations of whole genomes.",
  month    =  oct,
  year     =  2009,
  language = "en"
}

@ARTICLE{Lieberman-Aiden2009-nf,
  title    = "Comprehensive mapping of long-range interactions reveals folding
              principles of the human genome",
  author   = "Lieberman-Aiden, Erez and van Berkum, Nynke L and Williams, Louise
              and Imakaev, Maxim and Ragoczy, Tobias and Telling, Agnes and
              Amit, Ido and Lajoie, Bryan R and Sabo, Peter J and Dorschner,
              Michael O and Sandstrom, Richard and Bernstein, Bradley and
              Bender, M A and Groudine, Mark and Gnirke, Andreas and
              Stamatoyannopoulos, John and Mirny, Leonid A and Lander, Eric S
              and Dekker, Job",
  journal  = "Science",
  volume   =  326,
  number   =  5950,
  pages    = "289--293",
  abstract = "We describe Hi-C, a method that probes the three-dimensional
              architecture of whole genomes by coupling proximity-based ligation
              with massively parallel sequencing. We constructed spatial
              proximity maps of the human genome with Hi-C at a resolution of 1
              megabase. These maps confirm the presence of chromosome
              territories and the spatial proximity of small, gene-rich
              chromosomes. We identified an additional level of genome
              organization that is characterized by the spatial segregation of
              open and closed chromatin to form two genome-wide compartments. At
              the megabase scale, the chromatin conformation is consistent with
              a fractal globule, a knot-free, polymer conformation that enables
              maximally dense packing while preserving the ability to easily
              fold and unfold any genomic locus. The fractal globule is distinct
              from the more commonly used globular equilibrium model. Our
              results demonstrate the power of Hi-C to map the dynamic
              conformations of whole genomes.",
  month    =  oct,
  year     =  2009,
  language = "en"
}

@ARTICLE{Karaiskos2017-gf,
  title     = "The Drosophila embryo at single-cell transcriptome resolution",
  author    = "Karaiskos, Nikos and Wahle, Philipp and Alles, Jonathan and
               Boltengagen, Anastasiya and Ayoub, Salah and Kipar, Claudia and
               Kocks, Christine and Rajewsky, Nikolaus and Zinzen, Robert P",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science",
  volume    =  358,
  number    =  6360,
  pages     = "194--199",
  abstract  = "By the onset of morphogenesis, Drosophila embryos consist of
               about 6000 cells that express distinct gene combinations. Here,
               we used single-cell sequencing of precisely staged embryos and
               devised DistMap, a computational mapping strategy to reconstruct
               the embryo and to predict spatial gene expression approaching
               single-cell resolution. We produced a virtual embryo with about
               8000 expressed genes per cell. Our interactive Drosophila Virtual
               Expression eXplorer (DVEX) database generates three-dimensional
               virtual in situ hybridizations and computes gene expression
               gradients. We used DVEX to uncover patterned expression of
               transcription factors and long noncoding RNAs, as well as
               signaling pathway components. Spatial regulation of Hippo
               signaling during early embryogenesis suggests a mechanism for
               establishing asynchronous cell proliferation. Our approach is
               suitable to generate transcriptomic blueprints for other complex
               tissues.",
  month     =  oct,
  year      =  2017,
  language  = "en"
}

@ARTICLE{Seeger2004-gw,
  title    = "Gaussian processes for machine learning",
  author   = "Seeger, Matthias W",
  journal  = "Int. J. Neural Syst.",
  volume   =  14,
  number   =  2,
  pages    = "69--106",
  abstract = "Gaussian processes (GPs) are natural generalisations of
              multivariate Gaussian random variables to infinite (countably or
              continuous) index sets. GPs have been applied in a large number of
              fields to a diverse range of ends, and very many deep theoretical
              analyses of various properties are available. This paper gives an
              introduction to Gaussian processes on a fairly elementary level
              with special emphasis on characteristics relevant in machine
              learning. It draws explicit connections to branches such as spline
              smoothing models and support vector machines in which similar
              ideas have been investigated. Gaussian process models are
              routinely used to solve hard machine learning problems. They are
              attractive because of their flexible non-parametric nature and
              computational simplicity. Treated within a Bayesian framework,
              very powerful statistical methods can be implemented which offer
              valid estimates of uncertainties in our predictions and generic
              model selection procedures cast as nonlinear optimization
              problems. Their main drawback of heavy computational scaling has
              recently been alleviated by the introduction of generic sparse
              approximations.13,78,31 The mathematical literature on GPs is
              large and often uses deep concepts which are not required to fully
              understand most machine learning applications. In this tutorial
              paper, we aim to present characteristics of GPs relevant to
              machine learning and to show up precise connections to other
              ``kernel machines'' popular in the community. Our focus is on a
              simple presentation, but references to more detailed sources are
              provided.",
  month    =  apr,
  year     =  2004
}

@ARTICLE{Yu2009-zt,
  title     = "Gaussian-process factor analysis for low-dimensional single-trial
               analysis of neural population activity",
  author    = "Yu, Byron M and Cunningham, John P and Santhanam, Gopal and Ryu,
               Stephen I and Shenoy, Krishna V and Sahani, Maneesh",
  journal   = "J. Neurophysiol.",
  publisher = "American Physiological Society",
  volume    =  102,
  number    =  1,
  pages     = "614--635",
  abstract  = "We consider the problem of extracting smooth, low-dimensional
               neural trajectories that summarize the activity recorded
               simultaneously from many neurons on individual experimental
               trials. Beyond the benefit of visualizing the high-dimensional,
               noisy spiking activity in a compact form, such trajectories can
               offer insight into the dynamics of the neural circuitry
               underlying the recorded activity. Current methods for extracting
               neural trajectories involve a two-stage process: the spike trains
               are first smoothed over time, then a static
               dimensionality-reduction technique is applied. We first describe
               extensions of the two-stage methods that allow the degree of
               smoothing to be chosen in a principled way and that account for
               spiking variability, which may vary both across neurons and
               across time. We then present a novel method for extracting neural
               trajectories-Gaussian-process factor analysis (GPFA)-which
               unifies the smoothing and dimensionality-reduction operations in
               a common probabilistic framework. We applied these methods to the
               activity of 61 neurons recorded simultaneously in macaque
               premotor and motor cortices during reach planning and execution.
               By adopting a goodness-of-fit metric that measures how well the
               activity of each neuron can be predicted by all other recorded
               neurons, we found that the proposed extensions improved the
               predictive ability of the two-stage methods. The predictive
               ability was further improved by going to GPFA. From the extracted
               trajectories, we directly observed a convergence in neural state
               during motor planning, an effect that was shown indirectly by
               previous studies. We then show how such methods can be a powerful
               tool for relating the spiking activity across a neural population
               to the subject's behavior on a single-trial basis. Finally, to
               assess how well the proposed methods characterize neural
               population activity when the underlying time course is known, we
               performed simulations that revealed that GPFA performed tens of
               percent better than the best two-stage method.",
  month     =  jul,
  year      =  2009,
  language  = "en"
}

@ARTICLE{Wolf2018-sz,
  title    = "{SCANPY}: large-scale single-cell gene expression data analysis",
  author   = "Wolf, F Alexander and Angerer, Philipp and Theis, Fabian J",
  journal  = "Genome Biol.",
  volume   =  19,
  number   =  1,
  pages    =  15,
  abstract = "SCANPY is a scalable toolkit for analyzing single-cell gene
              expression data. It includes methods for preprocessing,
              visualization, clustering, pseudotime and trajectory inference,
              differential expression testing, and simulation of gene regulatory
              networks. Its Python-based implementation efficiently deals with
              data sets of more than one million cells (
              https://github.com/theislab/Scanpy ). Along with SCANPY, we
              present ANNDATA, a generic class for handling annotated data
              matrices ( https://github.com/theislab/anndata ).",
  month    =  feb,
  year     =  2018,
  keywords = "Bioinformatics; Clustering; Differential expression testing; Graph
              analysis; Machine learning; Pseudotemporal ordering; Scalability;
              Single-cell transcriptomics; Trajectory inference; Visualization",
  language = "en"
}

@ARTICLE{Sun2019-kj,
  title    = "Accuracy, robustness and scalability of dimensionality reduction
              methods for single-cell {RNA}-seq analysis",
  author   = "Sun, Shiquan and Zhu, Jiaqiang and Ma, Ying and Zhou, Xiang",
  journal  = "Genome Biol.",
  volume   =  20,
  number   =  1,
  pages    =  269,
  abstract = "BACKGROUND: Dimensionality reduction is an indispensable analytic
              component for many areas of single-cell RNA sequencing (scRNA-seq)
              data analysis. Proper dimensionality reduction can allow for
              effective noise removal and facilitate many downstream analyses
              that include cell clustering and lineage reconstruction.
              Unfortunately, despite the critical importance of dimensionality
              reduction in scRNA-seq analysis and the vast number of
              dimensionality reduction methods developed for scRNA-seq studies,
              few comprehensive comparison studies have been performed to
              evaluate the effectiveness of different dimensionality reduction
              methods in scRNA-seq. RESULTS: We aim to fill this critical
              knowledge gap by providing a comparative evaluation of a variety
              of commonly used dimensionality reduction methods for scRNA-seq
              studies. Specifically, we compare 18 different dimensionality
              reduction methods on 30 publicly available scRNA-seq datasets that
              cover a range of sequencing techniques and sample sizes. We
              evaluate the performance of different dimensionality reduction
              methods for neighborhood preserving in terms of their ability to
              recover features of the original expression matrix, and for cell
              clustering and lineage reconstruction in terms of their accuracy
              and robustness. We also evaluate the computational scalability of
              different dimensionality reduction methods by recording their
              computational cost. CONCLUSIONS: Based on the comprehensive
              evaluation results, we provide important guidelines for choosing
              dimensionality reduction methods for scRNA-seq data analysis. We
              also provide all analysis scripts used in the present study at
              www.xzlab.org/reproduce.html.",
  month    =  dec,
  year     =  2019,
  language = "en"
}

@ARTICLE{Wang2021-sz,
  title    = "{SPIN} reveals genome-wide landscape of nuclear
              compartmentalization",
  author   = "Wang, Yuchuan and Zhang, Yang and Zhang, Ruochi and van Schaik,
              Tom and Zhang, Liguo and Sasaki, Takayo and Peric-Hupkes, Daniel
              and Chen, Yu and Gilbert, David M and van Steensel, Bas and
              Belmont, Andrew S and Ma, Jian",
  journal  = "Genome Biol.",
  volume   =  22,
  number   =  1,
  pages    =  36,
  abstract = "We report SPIN, an integrative computational method to reveal
              genome-wide intranuclear chromosome positioning and nuclear
              compartmentalization relative to multiple nuclear structures,
              which are pivotal for modulating genome function. As a
              proof-of-principle, we use SPIN to integrate nuclear compartment
              mapping (TSA-seq and DamID) and chromatin interaction data (Hi-C)
              from K562 cells to identify 10 spatial compartmentalization states
              genome-wide relative to nuclear speckles, lamina, and putative
              associations with nucleoli. These SPIN states show novel patterns
              of genome spatial organization and their relation to other 3D
              genome features and genome function (transcription and replication
              timing). SPIN provides critical insights into nuclear spatial and
              functional compartmentalization.",
  month    =  jan,
  year     =  2021,
  keywords = "3D genome organization; Nuclear bodies; Nuclear
              compartmentalization; Probabilistic graphical model",
  language = "en"
}

@ARTICLE{Stein2005-af,
  title     = "{Space–Time} Covariance Functions",
  author    = "Stein, Michael L",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  100,
  number    =  469,
  pages     = "310--321",
  abstract  = "This work considers a number of properties of space?time
               covariance functions and how these relate to the spatial-temporal
               interactions of the process. First, it examines how the
               smoothness away from the origin of a space?time covariance
               function affects, for example, temporal correlations of spatial
               differences. Models that are not smoother away from the origin
               than they are at the origin, such as separable models, have a
               kind of discontinuity to certain correlations that one might wish
               to avoid in some circumstances. Smoothness away from the origin
               of a covariance function is shown to follow from the
               corresponding spectral density having derivatives with finite
               moments. These results are used to obtain a parametric class of
               spectral densities whose corresponding space?time covariance
               functions are infinitely differentiable away from the origin and
               that allows for essentially arbitrary and possibly different
               degrees of smoothness for the process in space and time. Second,
               this work considers models that are asymmetric in space?time; the
               covariance between site x at time t and site y at time s is
               different than the covariance between site x at time s and site y
               at time t. A general approach is described for generating
               asymmetric models from symmetric models by taking derivatives.
               Finally, the implications of a Markov assumption in time on
               space?time covariance functions for Gaussian processes are
               examined, and an explicit characterization of all such continuous
               covariance functions is given. Several of the new models
               described in this work are applied to wind data from Ireland.",
  month     =  mar,
  year      =  2005
}

@ARTICLE{Serra2017-xd,
  title    = "Automatic analysis and {3D}-modelling of Hi-{C} data using
              {TADbit} reveals structural features of the fly chromatin colors",
  author   = "Serra, François and Baù, Davide and Goodstadt, Mike and Castillo,
              David and Filion, Guillaume J and Marti-Renom, Marc A",
  journal  = "PLoS Comput. Biol.",
  volume   =  13,
  number   =  7,
  pages    = "e1005665",
  abstract = "The sequence of a genome is insufficient to understand all genomic
              processes carried out in the cell nucleus. To achieve this, the
              knowledge of its three-dimensional architecture is necessary.
              Advances in genomic technologies and the development of new
              analytical methods, such as Chromosome Conformation Capture (3C)
              and its derivatives, provide unprecedented insights in the spatial
              organization of genomes. Here we present TADbit, a computational
              framework to analyze and model the chromatin fiber in three
              dimensions. Our package takes as input the sequencing reads of
              3C-based experiments and performs the following main tasks: (i)
              pre-process the reads, (ii) map the reads to a reference genome,
              (iii) filter and normalize the interaction data, (iv) analyze the
              resulting interaction matrices, (v) build 3D models of selected
              genomic domains, and (vi) analyze the resulting models to
              characterize their structural properties. To illustrate the use of
              TADbit, we automatically modeled 50 genomic domains from the fly
              genome revealing differential structural features of the
              previously defined chromatin colors, establishing a link between
              the conformation of the genome and the local chromatin
              composition. TADbit provides three-dimensional models built from
              3C-based experiments, which are ready for visualization and for
              characterizing their relation to gene expression and epigenetic
              states. TADbit is an open-source Python library available for
              download from https://github.com/3DGenomes/tadbit.",
  month    =  jul,
  year     =  2017,
  language = "en"
}

@ARTICLE{Chari2023-tk,
  title     = "The specious art of single-cell genomics",
  author    = "Chari, Tara and Pachter, Lior",
  journal   = "PLoS Comput. Biol.",
  publisher = "Public Library of Science (PLoS)",
  volume    =  19,
  number    =  8,
  pages     = "e1011288",
  abstract  = "Dimensionality reduction is standard practice for filtering noise
               and identifying relevant features in large-scale data analyses.
               In biology, single-cell genomics studies typically begin with
               reduction to 2 or 3 dimensions to produce ``all-in-one'' visuals
               of the data that are amenable to the human eye, and these are
               subsequently used for qualitative and quantitative exploratory
               analysis. However, there is little theoretical support for this
               practice, and we show that extreme dimension reduction, from
               hundreds or thousands of dimensions to 2, inevitably induces
               significant distortion of high-dimensional datasets. We therefore
               examine the practical implications of low-dimensional embedding
               of single-cell data and find that extensive distortions and
               inconsistent practices make such embeddings counter-productive
               for exploratory, biological analyses. In lieu of this, we discuss
               alternative approaches for conducting targeted embedding and
               feature exploration to enable hypothesis-driven biological
               discovery.",
  month     =  aug,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Matthews2017-hy,
  title    = "Scalable Gaussian process inference using variational methods",
  author   = "Matthews, Alexander Graeme de Garis",
  abstract = "Gaussian processes can be used as priors on functions. The need
              for a flexible, principled, probabilistic model of functional
              relations is common in practice. Consequently, such an approach is
              demonstrably useful in a large variety of applications. Two
              challenges of Gaussian process modelling are often encountered.
              These are dealing with the adverse scaling with the number of data
              points and the lack of closed form posteriors when the likelihood
              is non-Gaussian. In this thesis, we study variational inference as
              a framework for meeting these challenges. An introductory chapter
              motivates the use of stochastic processes as priors, with a
              particular focus on Gaussian process modelling. A section on
              variational inference reviews the general definition of
              Kullback-Leibler divergence. The concept of prior conditional
              matching that is used throughout the thesis is contrasted to
              classical approaches to obtaining tractable variational
              approximating families. Various theoretical issues arising from
              the application of variational inference to the infinite
              dimensional Gaussian process setting are settled decisively. From
              this theory we are able to give a new argument for existing
              approaches to variational regression that settles debate about
              their applicability. This view on these methods justifies the
              principled extensions found in the rest of the work. The case of
              scalable Gaussian process classification is studied, both for its
              own merits and as a case study for non-Gaussian likelihoods in
              general. Using the resulting algorithms we find credible results
              on datasets of a scale and complexity that was not possible before
              our work. An extension to include Bayesian priors on model
              hyperparameters is studied alongside a new inference method that
              combines the benefits of variational sparsity and MCMC methods.
              The utility of such an approach is shown on a variety of example
              modelling tasks. We describe GPflow, a new Gaussian process
              software library that uses TensorFlow. Implementations of the
              variational algorithms discussed in the rest of the thesis are
              included as part of the software. We discuss the benefits of
              GPflow when compared to other similar software. Increased
              computational speed is demonstrated in relevant, timed,
              experimental comparisons.",
  month    =  mar,
  year     =  2017,
  keywords = "Gaussian process; Variational inference; Machine learning;
              Statistics; Bayesian inference",
  language = "en"
}

@ARTICLE{McInnes2018-ro,
  title     = "{UMAP}: Uniform Manifold Approximation and Projection",
  author    = "McInnes, Leland and Healy, John and Saul, Nathaniel and
               Großberger, Lukas",
  journal   = "J. Open Source Softw.",
  publisher = "The Open Journal",
  volume    =  3,
  number    =  29,
  pages     =  861,
  abstract  = "McInnes et al., (2018). UMAP: Uniform Manifold Approximation and
               Projection. Journal of Open Source Software, 3(29), 861,
               https://doi.org/10.21105/joss.00861",
  month     =  sep,
  year      =  2018
}

@ARTICLE{Holt2023-yf,
  title    = "Essential Aspects of Bayesian Data Imputation",
  author   = "Holt, William and Nguyen, Duy",
  abstract = "Data imputation holds significant importance in a variety of
              fields including risk management. Incomplete or missing data can
              hinder a thorough analysis of risks, making accurate
              decision-making challenging. By employing imputation techniques to
              fill in the gaps, risk managers can obtain a more comprehensive
              and reliable understanding of the underlying risk factors. This,
              in turn, enables them to make informed decisions and develop
              effective strategies for risk mitigation. This note introduces the
              concept Bayesian data imputation. We collect and provide
              backgrounds needed for Bayesian data imputation when missing data
              are missing at random. Numerical examples are provided for
              demonstration.",
  month    =  jun,
  year     =  2023
}

@ARTICLE{Chen2021-mi,
  title     = "A deep non-negative matrix factorization model for big data
               representation learning",
  author    = "Chen, Zhikui and Jin, Shan and Liu, Runze and Zhang, Jianing",
  journal   = "Front. Neurorobot.",
  publisher = "Frontiers Media SA",
  volume    =  15,
  pages     =  701194,
  abstract  = "Nowadays, deep representations have been attracting much
               attention owing to the great performance in various tasks.
               However, the interpretability of deep representations poses a
               vast challenge on real-world applications. To alleviate the
               challenge, a deep matrix factorization method with non-negative
               constraints is proposed to learn deep part-based representations
               of interpretability for big data in this paper. Specifically, a
               deep architecture with a supervisor network suppressing noise in
               data and a student network learning deep representations of
               interpretability is designed, which is an end-to-end framework
               for pattern mining. Furthermore, to train the deep matrix
               factorization architecture, an interpretability loss is defined,
               including a symmetric loss, an apposition loss, and a
               non-negative constraint loss, which can ensure the knowledge
               transfer from the supervisor network to the student network,
               enhancing the robustness of deep representations. Finally,
               extensive experimental results on two benchmark datasets
               demonstrate the superiority of the deep matrix factorization
               method.",
  month     =  jul,
  year      =  2021,
  keywords  = "deep representation learning; denoising autoencoder;
               interpretability; non-negative matrix factorization; supervisor
               network",
  language  = "en"
}

@BOOK{Bartholomew2011-vg,
  title     = "Latent Variable Models and Factor Analysis: A Unified Approach",
  author    = "Bartholomew, David J and Knott, Martin and Moustaki, Irini",
  publisher = "John Wiley \& Sons",
  abstract  = "Latent Variable Models and Factor Analysis provides a
               comprehensive and unified approach to factor analysis and latent
               variable modeling from a statistical perspective. This book
               presents a general framework to enable the derivation of the
               commonly used models, along with updated numerical examples.
               Nature and interpretation of a latent variable is also introduced
               along with related techniques for investigating dependency. This
               book: Provides a unified approach showing how such apparently
               diverse methods as Latent Class Analysis and Factor Analysis are
               actually members of the same family. Presents new material on
               ordered manifest variables, MCMC methods, non-linear models as
               well as a new chapter on related techniques for investigating
               dependency. Includes new sections on structural equation models
               (SEM) and Markov Chain Monte Carlo methods for parameter
               estimation, along with new illustrative examples. Looks at recent
               developments on goodness-of-fit test statistics and on non-linear
               models and models with mixed latent variables, both categorical
               and continuous. No prior acquaintance with latent variable
               modelling is pre-supposed but a broad understanding of
               statistical theory will make it easier to see the approach in its
               proper perspective. Applied statisticians, psychometricians,
               medical statisticians, biostatisticians, economists and social
               science researchers will benefit from this book.",
  month     =  jun,
  year      =  2011,
  language  = "en"
}

@ARTICLE{Bonilla2007-gw,
  title   = "Multi-task Gaussian Process Prediction",
  author  = "Bonilla, Edwin V and Chai, Kian and Williams, Christopher",
  journal = "Advances in neural information processing systems",
  year    =  2007
}

@INPROCEEDINGS{Turk1991-hp,
  title       = "Face recognition using eigenfaces",
  author      = "Turk, Matthew A and Pentland, Alex P",
  booktitle   = "Proceedings. 1991 IEEE computer society conference on computer
                 vision and pattern recognition",
  institution = "IEEE Computer Society",
  pages       = "586--587",
  year        =  1991
}

@ARTICLE{Maaten2008-iv,
  title    = "Visualizing Data using t-{SNE}",
  author   = "Maaten, L and Hinton, Geoffrey E",
  journal  = "Journal of Machine Learning Research",
  volume   =  9,
  number   =  86,
  pages    = "2579--2605",
  abstract = "We present a new technique called “t-SNE” that visualizes
              high-dimensional data by giving each datapoint a location in a two
              or three-dimensional map. The technique is a variation of
              Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is
              much easier to optimize, and produces significantly better
              visualizations by reducing the tendency to crowd points together
              in the center of the map. t-SNE is better than existing techniques
              at creating a single map that reveals structure at many different
              scales. This is particularly important for high-dimensional data
              that lie on several different, but related, low-dimensional
              manifolds, such as images of objects from multiple classes seen
              from multiple viewpoints. For visualizing the structure of very
              large datasets, we show how t-SNE can use random walks on
              neighborhood graphs to allow the implicit structure of all of the
              data to influence the way in which a subset of the data is
              displayed. We illustrate the performance of t-SNE on a wide
              variety of datasets and compare it with many other non-parametric
              visualization techniques, including Sammon mapping, Isomap, and
              Locally Linear Embedding. The visualizations produced by t-SNE are
              significantly better than those produced by the other techniques
              on almost all of the datasets.",
  year     =  2008
}

@INCOLLECTION{Quinonero-Candela2007-un,
  title     = "Approximation Methods for Gaussian process regression",
  author    = "Quiñonero-Candela, J and Rasmussen, C E and Williams, C K I",
  booktitle = "Large-Scale Kernel Machines",
  publisher = "MIT Press",
  address   = "London, England",
  pages     = "203--223",
  abstract  = "Autor: Quiñonero-Candela, J et al.; Genre: Buchkapitel; Im Druck
               veröffentlicht: 2007-08; Open Access; Titel: Approximation
               Methods for Gaussian Process Regression",
  month     =  aug,
  year      =  2007
}

@ARTICLE{Salimbeni2017-ds,
  title   = "Doubly stochastic variational inference for deep Gaussian processes",
  author  = "Salimbeni, Hugh and Deisenroth, Marc",
  journal = "Adv. Neural Inf. Process. Syst.",
  volume  =  30,
  year    =  2017
}

@ARTICLE{Dugas2000-ix,
  title   = "Incorporating second-order functional knowledge for better option
             pricing",
  author  = "Dugas, Charles and Bengio, Yoshua and Bélisle, François and Nadeau,
             Claude and Garcia, René",
  journal = "Adv. Neural Inf. Process. Syst.",
  volume  =  13,
  year    =  2000
}

@INPROCEEDINGS{Wu2022-fd,
  title     = "Variational nearest neighbor Gaussian process",
  author    = "Wu, Luhuan and Pleiss, Geoff and Cunningham, John P",
  editor    = "Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and
               Szepesvari, Csaba and Niu, Gang and Sabato, Sivan",
  booktitle = "Proceedings of the 39th International Conference on Machine
               Learning",
  publisher = "PMLR",
  volume    =  162,
  pages     = "24114--24130",
  abstract  = "Variational approximations to Gaussian processes (GPs) typically
               use a small set of inducing points to form a low-rank
               approximation to the covariance matrix. In this work, we instead
               exploit a sparse approximation of the precision matrix. We
               propose variational nearest neighbor Gaussian process (VNNGP),
               which introduces a prior that only retains correlations within
               $K$ nearest-neighboring observations, thereby inducing sparse
               precision structure. Using the variational framework, VNNGP’s
               objective can be factorized over both observations and inducing
               points, enabling stochastic optimization with a time complexity
               of $O(K^3)$. Hence, we can arbitrarily scale the inducing point
               size, even to the point of putting inducing points at every
               observed location. We compare VNNGP to other scalable GPs through
               various experiments, and demonstrate that VNNGP (1) can
               dramatically outperform low-rank methods, and (2) is less prone
               to overfitting than other nearest neighbor methods.",
  series    = "Proceedings of Machine Learning Research",
  year      =  2022
}

@ARTICLE{Lawrence2005-il,
  title     = "Probabilistic non-linear principal component analysis with
               Gaussian process latent variable models",
  author    = "Lawrence, N and Hyvärinen, A",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  abstract  = "Summarising a high dimensional data set with a low dimensional
               embedding is a standard approach for exploring its structure. In
               this paper we provide an overview of some existing techniques for
               discovering such embeddings. We then introduce a novel
               probabilistic interpretation of principal component analysis
               (PCA) that we term dual probabilistic PCA (DPPCA). The DPPCA
               model has the additional advantage that the linear mappings from
               the embedded space can easily be nonlinearised through Gaussian
               processes. We refer to …",
  year      =  2005
}

@ARTICLE{Lawrence2005-uu,
  title     = "Probabilistic non-linear principal component analysis with
               Gaussian process latent variable models",
  author    = "Lawrence, N and Hyvärinen, A",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  abstract  = "Summarising a high dimensional data set with a low dimensional
               embedding is a standard approach for exploring its structure. In
               this paper we provide an overview of some existing techniques for
               discovering such embeddings. We then introduce a novel
               probabilistic interpretation of principal component analysis
               (PCA) that we term dual probabilistic PCA (DPPCA). The DPPCA
               model has the additional advantage that the linear mappings from
               the embedded space can easily be nonlinearised through Gaussian
               processes. We refer to …",
  year      =  2005
}

@PHDTHESIS{Damianou2015-dy,
  title     = "Deep Gaussian Processes and Variational Propagation of
               Uncertainty",
  author    = "Damianou, Andreas",
  publisher = "University of Sheffield",
  abstract  = "Uncertainty propagation across components of complex
               probabilistic models is vital for improving regularisation.
               Unfortunately, for many interesting models based on non-linear
               Gaussian processes (GPs), straightforward propagation of
               uncertainty is computationally and mathematically intractable.
               This thesis is concerned with solving this problem through
               developing novel variational inference approaches. From a
               modelling perspective, a key contribution of the thesis is the
               development of deep Gaussian processes (deep GPs). Deep GPs
               generalise several interesting GP-based models and, hence,
               motivate the development of uncertainty propagation techniques.
               In a deep GP, each layer is modelled as the output of a
               multivariate GP, whose inputs are governed by another GP. The
               resulting model is no longer a GP but, instead, can learn much
               more complex interactions between data. In contrast to other deep
               models, all the uncertainty in parameters and latent variables is
               marginalised out and both supervised and unsupervised learning is
               handled. Two important special cases of a deep GP can
               equivalently be seen as its building components and,
               historically, were developed as such. Firstly, the variational
               GP-LVM is concerned with propagating uncertainty in Gaussian
               process latent variable models. Any observed inputs (e.g.
               temporal) can also be used to correlate the latent space
               posteriors. Secondly, this thesis develops manifold relevance
               determination (MRD) which considers a common latent space for
               multiple views. An adapted variational framework allows for
               strong model regularisation, resulting in rich latent space
               representations to be learned. The developed models are also
               equipped with algorithms that maximise the information
               communicated between their different stages using uncertainty
               propagation, to achieve improved learning when partially observed
               values are present. The developed methods are demonstrated in
               experiments with simulated and real data. The results show that
               the developed variational methodologies improve practical
               applicability by enabling automatic capacity control in the
               models, even when data are scarce.",
  month     =  jul,
  year      =  2015,
  school    = "University of Sheffield",
  language  = "en"
}

@ARTICLE{Lundberg2017-ol,
  title   = "A Unified Approach to Interpreting Model Predictions",
  author  = "Lundberg, Scott M and Lee, Su-In",
  journal = "Advances in Neural Information Processing Systems",
  volume  =  30,
  year    =  2017
}
